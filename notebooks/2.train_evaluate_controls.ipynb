{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c67966",
   "metadata": {},
   "source": [
    "MAIN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lggf.py\n",
    "# One-file script: training, 3-seed grid launcher, and aggregation.\n",
    "# Implements: 0, 1A, 1B, 1D, 2, 4\n",
    "# Requires: torch, torchvision, pycocotools, albumentations, numpy, tqdm\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import gc\n",
    "import json\n",
    "import copy\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import tempfile\n",
    "import warnings\n",
    "import subprocess\n",
    "import datetime\n",
    "from glob import glob\n",
    "from collections import OrderedDict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "from torchvision.models.detection import (\n",
    "    retinanet_resnet50_fpn,\n",
    "    RetinaNet_ResNet50_FPN_Weights,\n",
    ")\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "from torchvision.ops.misc import FrozenBatchNorm2d\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- Env & determinism --------------------------------\n",
    "os.environ.setdefault(\"CUDA_LAUNCH_BLOCKING\", \"1\")\n",
    "os.environ.setdefault(\"TORCH_SHOW_CPP_STACKTRACES\", \"1\")\n",
    "os.environ.setdefault(\"CUBLAS_WORKSPACE_CONFIG\", \":4096:8\")\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"max_split_size_mb:128\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"albumentations\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torchvision\")\n",
    "\n",
    "try:\n",
    "    from torch.amp import autocast, GradScaler\n",
    "    autocast_kwargs = dict(device_type=\"cuda\", dtype=torch.float16) if device.type == \"cuda\" else dict(dtype=torch.bfloat16)\n",
    "    scaler = GradScaler(device=\"cuda\") if device.type == \"cuda\" else None\n",
    "except Exception:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    autocast_kwargs = dict(dtype=torch.float16) if device.type == \"cuda\" else dict(dtype=torch.bfloat16)\n",
    "    scaler = GradScaler() if device.type == \"cuda\" else None\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if hasattr(torch.backends, \"cuda\") and hasattr(torch.backends.cuda, \"matmul\"):\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "    if hasattr(torch.backends, \"cudnn\") and hasattr(torch.backends.cudnn, \"allow_tf32\"):\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Albumentations\n",
    "    try:\n",
    "        if hasattr(A, \"set_seed\"):\n",
    "            A.set_seed(seed)\n",
    "        else:\n",
    "            from albumentations import random_utils\n",
    "            random_utils.set_seed(seed)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ----------------------------- Args -------------------------------------------\n",
    "def parse_args():\n",
    "    p = argparse.ArgumentParser(\"lgf trainer with grid + aggregation\")\n",
    "\n",
    "    # What to train\n",
    "    p.add_argument(\"--mode\", type=str, default=\"baseline\",\n",
    "                   choices=[\"baseline\",\"se\",\"cbam\",\"lgf_sum\",\"lgf_softmax\",\"lgf_gated\",\"lgf_gated_spatial\"])\n",
    "    p.add_argument(\"--insert-level\", type=str, default=\"C3\", choices=[\"C3\",\"C4\",\"C5\"])  # 1B\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--exp-name\", type=str, default=None)\n",
    "\n",
    "    # Dataset flags (1A)\n",
    "    p.add_argument(\"--dataset\", type=str, default=\"coco_nw\",\n",
    "                   choices=[\"coco_nw\",\"coco_weather\",\"acdc\",\"custom\"])\n",
    "    p.add_argument(\"--train-img\", type=str, default=None)\n",
    "    p.add_argument(\"--train-ann\", type=str, default=None)\n",
    "    p.add_argument(\"--val-img\", type=str, default=None)\n",
    "    p.add_argument(\"--val-ann\", type=str, default=None)\n",
    "\n",
    "    # Performance knobs (1D)\n",
    "    p.add_argument(\"--num-workers\", type=int, default=8)\n",
    "    p.add_argument(\"--prefetch-factor\", type=int, default=4)\n",
    "\n",
    "    # Training schedule\n",
    "    p.add_argument(\"--epochs\", type=int, default=80)\n",
    "    p.add_argument(\"--batch-size\", type=int, default=4)\n",
    "    p.add_argument(\"--accum-steps\", type=int, default=4)\n",
    "    p.add_argument(\"--base-lr\", type=float, default=0.005)\n",
    "    p.add_argument(\"--warmup-epochs\", type=int, default=2)\n",
    "    p.add_argument(\"--lr-milestones\", type=int, nargs=\"*\", default=[40,60])\n",
    "    p.add_argument(\"--img-size\", type=int, default=640)\n",
    "\n",
    "    # Grid runner (2)\n",
    "    p.add_argument(\"--run-grid\", action=\"store_true\")\n",
    "    p.add_argument(\"--grid-seeds\", type=int, nargs=\"*\", default=[42,1337,2025])\n",
    "    p.add_argument(\"--grid-datasets\", type=str, nargs=\"*\", default=None)\n",
    "    p.add_argument(\"--grid-levels\", type=str, nargs=\"*\", default=[\"C3\"])\n",
    "    p.add_argument(\"--grid-modes\", type=str, nargs=\"*\", default=None)\n",
    "    p.add_argument(\"--subprocess\", action=\"store_true\", help=\"force subprocess grid even in notebook\")\n",
    "\n",
    "    # Aggregation (4)\n",
    "    p.add_argument(\"--aggregate\", action=\"store_true\")\n",
    "    p.add_argument(\"--agg-datasets\", type=str, nargs=\"*\", default=None)\n",
    "    p.add_argument(\"--agg-levels\", type=str, nargs=\"*\", default=[\"C3\"])\n",
    "    p.add_argument(\"--agg-modes\", type=str, nargs=\"*\", default=None)\n",
    "    p.add_argument(\"--agg-seeds\", type=int, nargs=\"*\", default=[42,1337,2025])\n",
    "\n",
    "    # Jupyter friendliness\n",
    "    args, _ = p.parse_known_args()\n",
    "    return args\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "# ------------------------- Experiment configs ---------------------------------\n",
    "BASELINE_CONFIG = dict(BRANCH_PRESET=\"none\", gating_type=\"none\", block_type=\"none\",\n",
    "                       description=\"BASELINE: RetinaNet without custom blocks\")\n",
    "\n",
    "lgf_SUM_CONFIG      = dict(BRANCH_PRESET=\"local_global\", gating_type=\"sum\",          block_type=\"lgf\", description=\"lgf: local+global, sum\")\n",
    "lgf_SOFTMAX_CONFIG  = dict(BRANCH_PRESET=\"local_global\", gating_type=\"softmax\",      block_type=\"lgf\", description=\"lgf: local+global, softmax\")\n",
    "lgf_GATED_CONFIG    = dict(BRANCH_PRESET=\"local_global\", gating_type=\"gated\",        block_type=\"lgf\", description=\"lgf: local+global, sigmoid gate\")\n",
    "lgf_GATED_SP_CONFIG = dict(BRANCH_PRESET=\"local_global\", gating_type=\"gated_spatial\",block_type=\"lgf\", description=\"lgf: local+global, spatial gate\")\n",
    "\n",
    "CONFIG_MAP = {\n",
    "    \"baseline\": BASELINE_CONFIG,\n",
    "    \"lgf_sum\": lgf_SUM_CONFIG,\n",
    "    \"lgf_softmax\": lgf_SOFTMAX_CONFIG,\n",
    "    \"lgf_gated\": lgf_GATED_CONFIG,\n",
    "    \"lgf_gated_spatial\": lgf_GATED_SP_CONFIG,\n",
    "    \"se\": dict(BRANCH_PRESET=\"none\", gating_type=\"none\", block_type=\"se\",   description=\"SE before FPN\"),\n",
    "    \"cbam\": dict(BRANCH_PRESET=\"none\", gating_type=\"none\", block_type=\"cbam\", description=\"CBAM before FPN\"),\n",
    "}\n",
    "\n",
    "CURRENT_CONFIG = CONFIG_MAP[args.mode]\n",
    "LEVEL_MAP = {\"C3\":\"layer2\", \"C4\":\"layer3\", \"C5\":\"layer4\"}  # 1B\n",
    "\n",
    "# ------------------------- Anchors & helpers ----------------------------------\n",
    "def _probe_feature_names(backbone: nn.Module) -> list:\n",
    "    with torch.no_grad():\n",
    "        x = torch.zeros(1,3,args.img_size,args.img_size, device=next(backbone.parameters()).device)\n",
    "        feats = backbone(x)\n",
    "        if not isinstance(feats, OrderedDict):\n",
    "            raise RuntimeError(\"Backbone must return OrderedDict of features\")\n",
    "        return list(feats.keys())\n",
    "\n",
    "_SIZE_MAP = {\n",
    "    \"0\": (32,48,64),\n",
    "    \"1\": (64,96,128),\n",
    "    \"2\": (128,192,256),\n",
    "    \"3\": (256,384,512),\n",
    "    \"p6\": (256,384,512),\n",
    "    \"pool\": (384,512,640),\n",
    "    \"p7\": (384,512,640),\n",
    "}\n",
    "\n",
    "FORCE_STOCK_ANCHORS = False\n",
    "_STOCK_AG = None\n",
    "def get_stock_anchor_generator():\n",
    "    global _STOCK_AG\n",
    "    if _STOCK_AG is None:\n",
    "        _STOCK_AG = retinanet_resnet50_fpn(weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1).anchor_generator\n",
    "    return _STOCK_AG\n",
    "\n",
    "def make_anchor_generator_for(backbone: nn.Module) -> AnchorGenerator:\n",
    "    names = _probe_feature_names(backbone)\n",
    "    try:\n",
    "        sizes = tuple(_SIZE_MAP[n] for n in names)\n",
    "    except KeyError as e:\n",
    "        raise RuntimeError(f\"No anchor size tuple for feature '{e.args[0]}'. Backbone keys={names}\")\n",
    "    ratios = ((0.5,1.0,2.0),) * len(sizes)\n",
    "    return AnchorGenerator(sizes=sizes, aspect_ratios=ratios)\n",
    "\n",
    "# ---------------------------- Blocks ------------------------------------------\n",
    "class StableLGFBlock(nn.Module):\n",
    "    def __init__(self, channels, branches=(\"local\",\"global\"), gating_type=\"sum\", norm_groups=32, squeeze_ratio=16):\n",
    "        super().__init__()\n",
    "        self.branches = tuple(branches)\n",
    "        self.gating_type = gating_type\n",
    "        self.num_branches = len(self.branches)\n",
    "        self.save_maps = False\n",
    "        self.viz_cache = {}\n",
    "        def GN(c): return nn.GroupNorm(norm_groups, c)\n",
    "\n",
    "        # Local branch\n",
    "        self.local = None\n",
    "        if \"local\" in self.branches:\n",
    "            self.local = nn.Sequential(\n",
    "                nn.Conv2d(channels, channels, 3, padding=1, groups=channels, bias=False),\n",
    "                nn.Conv2d(channels, channels, 1, bias=False),\n",
    "                GN(channels), nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        # Global branch\n",
    "        self.global_branch = None\n",
    "        if \"global\" in self.branches:\n",
    "            self.global_branch = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Conv2d(channels, channels, 1, bias=False),\n",
    "                GN(channels), nn.SiLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        # Gates\n",
    "        if self.num_branches > 1:\n",
    "            if self.gating_type == \"softmax\":\n",
    "                self.temperature = nn.Parameter(torch.tensor(1.0))\n",
    "                self.branch_weights = nn.Parameter(torch.ones(self.num_branches))\n",
    "            elif self.gating_type == \"gated\":\n",
    "                hid = max(channels // squeeze_ratio, 4)\n",
    "                self.temperature = nn.Parameter(torch.tensor(1.0))\n",
    "                self.gate_mlp = nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
    "                    nn.Linear(channels, hid), nn.ReLU(inplace=True),\n",
    "                    nn.Linear(hid, self.num_branches)\n",
    "                )\n",
    "                nn.init.zeros_(self.gate_mlp[-1].weight); nn.init.zeros_(self.gate_mlp[-1].bias)\n",
    "            elif self.gating_type == \"gated_spatial\":\n",
    "                r = 4\n",
    "                self.temperature = nn.Parameter(torch.tensor(1.0))\n",
    "                self.gate_reduce = nn.Conv2d(channels, channels//r, 1, bias=False)\n",
    "                self.gate_expand = nn.Conv2d(channels//r, 2*channels, 1, bias=True)\n",
    "                self.gate_norm   = nn.GroupNorm(num_groups=norm_groups, num_channels=2*channels)\n",
    "                nn.init.zeros_(self.gate_expand.weight); nn.init.zeros_(self.gate_expand.bias)\n",
    "\n",
    "        self.gamma = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "    def enable_visualization(self, enable=True):\n",
    "        self.save_maps = bool(enable)\n",
    "        if not enable:\n",
    "            self.viz_cache = {}\n",
    "\n",
    "    def _broadcast(self, s, like):\n",
    "        if s.dim() == 1:\n",
    "            s = s.view(-1,1,1,1)\n",
    "        return s.expand_as(like)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = []\n",
    "        L = self.local(x) if self.local is not None else None\n",
    "        if L is not None: feats.append(L)\n",
    "        G = None\n",
    "        if self.global_branch is not None:\n",
    "            g = self.global_branch(x)\n",
    "            G = g.expand_as(x)\n",
    "            feats.append(G)\n",
    "\n",
    "        if len(feats) == 1:\n",
    "            out = feats[0]\n",
    "        else:\n",
    "            if self.gating_type == \"sum\":\n",
    "                out = feats[0] + feats[1]\n",
    "                wL = torch.full_like(L, 0.5); wG = torch.full_like(G, 0.5)\n",
    "            elif self.gating_type == \"softmax\":\n",
    "                tau = F.softplus(self.temperature) + 1e-3\n",
    "                w = F.softmax(self.branch_weights / tau, dim=0)\n",
    "                out = w[0]*feats[0] + w[1]*feats[1]\n",
    "                wL = self._broadcast(w[0], L); wG = self._broadcast(w[1], G)\n",
    "            elif self.gating_type == \"gated\":\n",
    "                with torch.cuda.amp.autocast(enabled=False):\n",
    "                    logits = self.gate_mlp(x.float())\n",
    "                    tau = F.softplus(self.temperature.float()) + 1e-3\n",
    "                    logits = logits.clamp_(-15,15)\n",
    "                    w32 = torch.sigmoid(logits / tau)\n",
    "                w = w32.to(dtype=x.dtype)\n",
    "                wL = self._broadcast(w[:,0], L); wG = self._broadcast(w[:,1], G)\n",
    "                out = wL*L + wG*G\n",
    "            elif self.gating_type == \"gated_spatial\":\n",
    "                h = F.relu(self.gate_reduce(x), inplace=True)\n",
    "                logits = self.gate_expand(h)\n",
    "                logits = self.gate_norm(logits)\n",
    "                with torch.cuda.amp.autocast(enabled=False):\n",
    "                    logits32 = logits.float().clamp_(-15,15)\n",
    "                    tau = F.softplus(self.temperature.float()) + 1e-3\n",
    "                    w = torch.sigmoid(logits32 / tau)\n",
    "                w = w.to(dtype=x.dtype)\n",
    "                N, twoC, H, W = w.shape\n",
    "                C = twoC//2\n",
    "                w = w.view(N,2,C,H,W)\n",
    "                wL, wG = w[:,0], w[:,1]\n",
    "                out = wL*L + wG*G\n",
    "            else:\n",
    "                out = feats[0] + feats[1]\n",
    "\n",
    "        out = x + self.gamma*out\n",
    "        if self.save_maps:\n",
    "            self.viz_cache = {\"L\": (L.detach() if L is not None else None),\n",
    "                              \"G\": (G.detach() if G is not None else None)}\n",
    "        return out\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc  = nn.Sequential(\n",
    "            nn.Linear(channels, channels//reduction, bias=False), nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels//reduction, channels, bias=False), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        b,c,_,_ = x.shape\n",
    "        y = self.fc(self.avg(x).view(b,c)).view(b,c,1,1)\n",
    "        return x * y\n",
    "\n",
    "# class CBAMBlock(nn.Module):\n",
    "#     def __init__(self, channels, reduction=16, k=7):\n",
    "#         super().__init__()\n",
    "#         self.avg = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.maxp = nn.AdaptiveMaxPool2d(1)\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Conv2d(channels, channels//reduction, 1, bias=False), nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(channels//reduction, channels, 1, bias=False)\n",
    "#         )\n",
    "#         self.sigc = nn.Sigmoid()\n",
    "#         self.convs = nn.Conv2d(2,1,k,padding=k//2,bias=False)\n",
    "#         self.sigs = nn.Sigmoid()\n",
    "#     def forward(self, x):\n",
    "#         ca = self.fc(self.avg(x)) + self.fc(self.maxp(x))\n",
    "#         x = x * self.sigc(ca)\n",
    "#         s = torch.cat([x.mean(1,True), x.amax(1,True)], dim=1)\n",
    "#         return x * self.sigs(self.convs(s))\n",
    "\n",
    "class CBAMBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Determinism-safe CBAM.\n",
    "    - Channel attention: avg pool + softmax-pooling over HxW (approximates max) -> shared MLP\n",
    "    - Spatial attention: concat(mean over C, softmax-pooling over C) -> 7x7 conv\n",
    "    The softmax pooling avoids adaptive_max_pool2d backward, which is non-deterministic on CUDA.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction=16, k=5, beta=20.0):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.avg = nn.AdaptiveAvgPool2d(1)  # deterministic\n",
    "        # shared MLP for channel attention\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction, channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigc = nn.Sigmoid()\n",
    "        # spatial attention\n",
    "        self.convs = nn.Conv2d(2, 1, k, padding=k // 2, bias=False)\n",
    "        self.sigs = nn.Sigmoid()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _normalize_stable(self, x, dim):\n",
    "        # subtract max along 'dim' for numerical stability, keep graph by doing it outside no_grad in callers\n",
    "        return x - x.max(dim=dim, keepdim=True).values\n",
    "\n",
    "    def _softmax_pool_spatial(self, x):\n",
    "        # softmax over H*W per channel, returns [B,C,1,1]\n",
    "        B, C, H, W = x.shape\n",
    "        x_flat = x.view(B, C, H * W)\n",
    "        # stabilize\n",
    "        x_norm = x_flat - x_flat.max(dim=2, keepdim=True).values\n",
    "        w = F.softmax(self.beta * x_norm, dim=2)\n",
    "        pooled = (w * x_flat).sum(dim=2)  # [B,C]\n",
    "        return pooled.view(B, C, 1, 1)\n",
    "\n",
    "    def _softmax_pool_channel(self, x):\n",
    "        # softmax over C per spatial location, returns [B,1,H,W]\n",
    "        B, C, H, W = x.shape\n",
    "        x_hw_c = x.permute(0, 2, 3, 1)              # [B,H,W,C]\n",
    "        x_norm = x_hw_c - x_hw_c.max(dim=3, keepdim=True).values\n",
    "        w = F.softmax(self.beta * x_norm, dim=3)    # [B,H,W,C]\n",
    "        pooled = (w * x_hw_c).sum(dim=3, keepdim=True)  # [B,H,W,1]\n",
    "        return pooled.permute(0, 3, 1, 2)           # [B,1,H,W]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Channel attention\n",
    "        avg_pool = self.avg(x)\n",
    "        smx_pool = self._softmax_pool_spatial(x)\n",
    "        ca = self.fc(avg_pool) + self.fc(smx_pool)\n",
    "        x = x * self.sigc(ca)\n",
    "\n",
    "        # Spatial attention\n",
    "        s_mean = x.mean(dim=1, keepdim=True)\n",
    "        s_softmax_max = self._softmax_pool_channel(x)\n",
    "        s = torch.cat([s_mean, s_softmax_max], dim=1)\n",
    "        sa = self.sigs(self.convs(s))\n",
    "        return x * sa\n",
    "\n",
    "# ----------------------------- Dataset (1A, 1D) -------------------------------\n",
    "def select_dataset_by_name(name: str):\n",
    "    # Defaults from your code for COCO Non-Weather; others can be overridden via flags.\n",
    "    if name == \"coco_nw\":\n",
    "        return (\n",
    "            \"/nas.dbms/asera/PROJECTS/DATASET/COCO/non_weather-mini/images/train2017_non_weather-2400k6c\",\n",
    "            \"/nas.dbms/asera/PROJECTS/DATASET/COCO/non_weather-mini/annotations/mini_train2017_non_weather-2400k6c.json\",\n",
    "            \"/nas.dbms/asera/PROJECTS/DATASET/COCO/non_weather-mini/images/val2017_non_weather-500k6c\",\n",
    "            \"/nas.dbms/asera/PROJECTS/DATASET/COCO/non_weather-mini/annotations/mini_val2017_non_weather-500k6c.json\"\n",
    "\n",
    "            # \"/root/COCO/images/train2017_non_weather-2400k6c\",\n",
    "            # \"/root/COCO/annotations/mini_train2017_non_weather-2400k6c.json\",\n",
    "            # \"/root/COCO/images/val2017_non_weather-500k6c\",\n",
    "            # \"/root/COCO/annotations/mini_val2017_non_weather-500k6c.json\"\n",
    "        )\n",
    "    elif name == \"acdc\":\n",
    "        return (\n",
    "            \"/nas.dbms/asera/PROJECTS/DATASET/ACDC-1/ACDC-1-NEW/images/train\",\n",
    "            \"/nas.dbms/asera/PROJECTS/DATASET/ACDC-1/ACDC-1-NEW/annotations/mini_train.json\",\n",
    "            \"/nas.dbms/asera/PROJECTS/DATASET/ACDC-1/ACDC-1-NEW/images/val\",\n",
    "            \"/nas.dbms/asera/PROJECTS/DATASET/ACDC-1/ACDC-1-NEW/annotations/mini_val.json\"\n",
    "        )\n",
    "    elif name == \"coco_weather\":\n",
    "        # Fill these to your synthetic-weather paths or pass --train-img/--train-ann/--val-img/--val-ann\n",
    "        return (\n",
    "            \"/nas.dbms/asera/PROJECTS/DATASET/COCO/weather-mini/images/train2017_weather-2400k6c\",\n",
    "            \"/nas.dbms/asera/PROJECTS/DATASET/COCO/weather-mini/annotations/mini_train2017_weather-2400k6c.json\", \n",
    "            \"/nas.dbms/asera/PROJECTS/DATASET/COCO/weather-mini/images/val2017_weather-500k6c\",\n",
    "            \"/nas.dbms/asera/PROJECTS/DATASET/COCO/weather-mini/annotations/mini_val2017_weather-500k6c.json\"\n",
    "        \n",
    "            # \"/root/COCO/images/train2017_weather-2400k6c\",\n",
    "            # \"/root/COCO/annotations/mini_train2017_weather-2400k6c.json\",\n",
    "            # \"/root/COCO/images/val2017_weather-500k6c\",\n",
    "            # \"/root/COCO/annotations/mini_val2017_weather-500k6c.json\"\n",
    "\n",
    "        )\n",
    "        # raise RuntimeError(\"Set --train-img/--train-ann/--val-img/--val-ann for coco_weather.\")\n",
    "    else:  # custom\n",
    "        raise RuntimeError(\"Use --train-img/--train-ann/--val-img/--val-ann for dataset=custom.\")\n",
    "\n",
    "def patch_annotations_once(ann_file):\n",
    "    with open(ann_file,\"r\") as f: data = json.load(f)\n",
    "    if \"info\" not in data:\n",
    "        data[\"info\"] = {\"description\":\"Patched COCO dataset\",\"version\":\"1.0\"}\n",
    "        with tempfile.NamedTemporaryFile(\"w+\",suffix=\".json\",delete=False) as tmp:\n",
    "            json.dump(data,tmp); tmp.flush()\n",
    "            return tmp.name\n",
    "    return ann_file\n",
    "\n",
    "class COCODataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_folder, ann_file, transforms=None, train=False):\n",
    "        self.img_folder = img_folder\n",
    "        self.coco = COCO(ann_file)\n",
    "        self.transforms = transforms\n",
    "        self.train = train\n",
    "        valid_cat_ids = sorted(self.coco.getCatIds())\n",
    "        self.cat_id_to_label = {cid:i for i,cid in enumerate(valid_cat_ids)}\n",
    "        self.label_to_cat_id = {v:k for k,v in self.cat_id_to_label.items()}\n",
    "        # expose number of classes for model construction\n",
    "        self.num_classes = len(valid_cat_ids)\n",
    "        self.ids = sorted(self.coco.imgs.keys())\n",
    "        # Optional ablation subset\n",
    "        k_env = os.getenv(\"MAX_TRAIN_IMAGES\")\n",
    "        if self.train and k_env:\n",
    "            k = min(int(k_env), len(self.ids))\n",
    "            rng = np.random.default_rng(12345)\n",
    "            self.ids = rng.choice(self.ids, size=k, replace=False).tolist()\n",
    "\n",
    "    def __len__(self): return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "        info = self.coco.loadImgs(img_id)[0]\n",
    "        path = os.path.join(self.img_folder, info[\"file_name\"])\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            img = np.zeros((info[\"height\"], info[\"width\"], 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        boxes, labels = [], []\n",
    "        for a in anns:\n",
    "            x,y,w,h = a[\"bbox\"]\n",
    "            if w>1 and h>1:\n",
    "                boxes.append([x,y,x+w,y+h])\n",
    "                labels.append(self.cat_id_to_label[a[\"category_id\"]])\n",
    "\n",
    "        if self.transforms:\n",
    "            t = self.transforms(image=img, bboxes=boxes, labels=labels)\n",
    "            img, boxes, labels = t[\"image\"], t[\"bboxes\"], t[\"labels\"]\n",
    "        if img.dtype == torch.uint8:\n",
    "            img = img.float()/255.0\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32).reshape(-1,4)\n",
    "        labels = torch.tensor([int(l) for l in labels], dtype=torch.int64)\n",
    "        target = {\"boxes\": boxes, \"labels\": labels, \"image_id\": torch.tensor([img_id]),\n",
    "                  \"orig_size\": torch.tensor([info[\"width\"], info[\"height\"]])}\n",
    "        return img, target\n",
    "\n",
    "def get_transform(train=True):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            ToTensorV2(),\n",
    "        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels'], min_area=1, min_visibility=0.1, check_each_transform=True))\n",
    "    else:\n",
    "        return A.Compose([ToTensorV2()],\n",
    "            bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels'], min_area=1, min_visibility=0.1, check_each_transform=True))\n",
    "\n",
    "def collate_fn(batch): return tuple(zip(*batch))\n",
    "\n",
    "def build_datasets_and_loaders(seed, dataset_code, overrides):\n",
    "    set_seed(seed)\n",
    "    if overrides[\"train_img\"] and overrides[\"train_ann\"] and overrides[\"val_img\"] and overrides[\"val_ann\"]:\n",
    "        tr_img, tr_ann, va_img, va_ann = overrides[\"train_img\"], overrides[\"train_ann\"], overrides[\"val_img\"], overrides[\"val_ann\"]\n",
    "    else:\n",
    "        tr_img, tr_ann, va_img, va_ann = select_dataset_by_name(dataset_code)\n",
    "    va_ann = patch_annotations_once(va_ann)\n",
    "    train_dataset = COCODataset(tr_img, tr_ann, transforms=get_transform(train=True),  train=True)\n",
    "    val_dataset   = COCODataset(va_img, va_ann, transforms=get_transform(train=False), train=False)\n",
    "\n",
    "    g = torch.Generator(); g.manual_seed(seed)\n",
    "    common = dict(collate_fn=collate_fn, worker_init_fn=worker_init_fn, pin_memory=True, generator=g)\n",
    "    if args.num_workers > 0:\n",
    "        common.update(num_workers=args.num_workers, persistent_workers=True, prefetch_factor=args.prefetch_factor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True,  **common)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=args.batch_size, shuffle=False, drop_last=False, **common)\n",
    "    return train_dataset, val_dataset, train_loader, val_loader, va_ann\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(int(worker_seed)); random.seed(int(worker_seed))\n",
    "    try:\n",
    "        if hasattr(A, \"set_seed\"):\n",
    "            A.set_seed(int(worker_seed))\n",
    "        else:\n",
    "            from albumentations import random_utils\n",
    "            random_utils.set_seed(int(worker_seed))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ------------------------------ Model -----------------------------------------\n",
    "def convert_bn_to_gn(module, num_groups=32, convert_frozen=False):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.BatchNorm2d):\n",
    "            setattr(module, name, nn.GroupNorm(num_groups=num_groups, num_channels=child.num_features))\n",
    "        elif convert_frozen and isinstance(child, FrozenBatchNorm2d):\n",
    "            setattr(module, name, nn.GroupNorm(num_groups=num_groups, num_channels=child.num_features))\n",
    "        else:\n",
    "            convert_bn_to_gn(child, num_groups=num_groups, convert_frozen=convert_frozen)\n",
    "    return module\n",
    "\n",
    "def get_block(channels, block_type, branches, gating_type):\n",
    "    if block_type == \"lgf\":\n",
    "        return StableLGFBlock(channels, branches=branches, gating_type=gating_type)\n",
    "    if block_type == \"se\":\n",
    "        return SEBlock(channels)\n",
    "    if block_type == \"cbam\":\n",
    "        return CBAMBlock(channels)\n",
    "    return nn.Identity()\n",
    "\n",
    "class CustomBackboneBlockBeforeFPN(nn.Module):\n",
    "    def __init__(self, backbone_with_fpn, selected_levels):\n",
    "        super().__init__()\n",
    "        self.body = backbone_with_fpn.body\n",
    "        self.fpn  = backbone_with_fpn.fpn\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feats = self.body(torch.zeros(1,3,224,224))\n",
    "            fpn_feats = self.fpn(feats)\n",
    "        actual_keys = list(feats.keys())\n",
    "        semantic_to_actual = {\n",
    "            \"layer1\": actual_keys[0] if len(actual_keys)>0 else None,\n",
    "            \"layer2\": actual_keys[1] if len(actual_keys)>1 else None,\n",
    "            \"layer3\": actual_keys[2] if len(actual_keys)>2 else None,\n",
    "            \"layer4\": actual_keys[3] if len(actual_keys)>3 else None,\n",
    "        }\n",
    "        wanted = []\n",
    "        for lvl in selected_levels:\n",
    "            if lvl in actual_keys: wanted.append(lvl)\n",
    "            elif lvl in semantic_to_actual and semantic_to_actual[lvl] is not None: wanted.append(semantic_to_actual[lvl])\n",
    "        self.selected_actual = wanted\n",
    "\n",
    "        self.block_fpn_in = nn.ModuleDict()\n",
    "        for k in self.selected_actual:\n",
    "            C = feats[k].shape[1]\n",
    "            self.block_fpn_in[str(k)] = get_block(C, CURRENT_CONFIG.get(\"block_type\",\"none\"),\n",
    "                                                  (\"local\",\"global\") if CURRENT_CONFIG[\"BRANCH_PRESET\"]==\"local_global\" else (),\n",
    "                                                  CURRENT_CONFIG[\"gating_type\"])\n",
    "\n",
    "        first_out = next(iter(fpn_feats.keys()))\n",
    "        self.out_channels = fpn_feats[first_out].shape[1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.body(x)\n",
    "        for k in self.selected_actual:\n",
    "            feats[k] = self.block_fpn_in[str(k)](feats[k])\n",
    "        return self.fpn(feats)\n",
    "\n",
    "def build_model(num_classes, insert_level):\n",
    "    pretrained = retinanet_resnet50_fpn(weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1)\n",
    "    convert_bn_to_gn(pretrained.backbone.body, num_groups=32, convert_frozen=False)\n",
    "\n",
    "    sel_levels = [LEVEL_MAP[insert_level]] if CURRENT_CONFIG.get(\"block_type\",\"none\") != \"none\" else []\n",
    "    if sel_levels:\n",
    "        bb = CustomBackboneBlockBeforeFPN(pretrained.backbone, selected_levels=sel_levels)\n",
    "    else:\n",
    "        bb = pretrained.backbone\n",
    "\n",
    "    ag = get_stock_anchor_generator() if FORCE_STOCK_ANCHORS else make_anchor_generator_for(bb)\n",
    "    model = torchvision.models.detection.RetinaNet(\n",
    "        backbone=bb,\n",
    "        num_classes=num_classes,\n",
    "        anchor_generator=ag,\n",
    "        head=pretrained.head,\n",
    "        transform=pretrained.transform,\n",
    "        detections_per_img=100,\n",
    "        nms_thresh=0.5,\n",
    "        score_thresh=0.05,\n",
    "    )\n",
    "\n",
    "    # Update cls head for our class count\n",
    "    in_ch = model.head.classification_head.cls_logits.in_channels\n",
    "    n_anchors = model.head.classification_head.num_anchors\n",
    "    model.head.classification_head.cls_logits = nn.Conv2d(in_ch, n_anchors*num_classes, kernel_size=3, padding=1)\n",
    "    model.head.classification_head.num_classes = num_classes\n",
    "    torch.nn.init.normal_(model.head.classification_head.cls_logits.weight, std=0.01)\n",
    "    prior_prob = 0.01\n",
    "    bias_value = -torch.log(torch.tensor((1.0 - prior_prob) / prior_prob))\n",
    "    torch.nn.init.constant_(model.head.classification_head.cls_logits.bias, bias_value)\n",
    "    return model\n",
    "\n",
    "# ----------------------------- Eval & logging ---------------------------------\n",
    "def coco_evaluation(model, data_loader, ann_file, device):\n",
    "    coco_gt = COCO(ann_file)\n",
    "    detections = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            images = [im.to(device) for im in images]\n",
    "            outputs = model(images)\n",
    "            for i,out in enumerate(outputs):\n",
    "                img_id = int(targets[i][\"image_id\"].item())\n",
    "                boxes = out[\"boxes\"].detach().cpu().numpy()\n",
    "                scores = out[\"scores\"].detach().cpu().numpy()\n",
    "                labels = out[\"labels\"].detach().cpu().numpy()\n",
    "                for b,s,l in zip(boxes,scores,labels):\n",
    "                    x1,y1,x2,y2 = b\n",
    "                    cat = data_loader.dataset.label_to_cat_id[int(l)] if hasattr(data_loader.dataset,\"label_to_cat_id\") else int(l)\n",
    "                    detections.append({\"image_id\":img_id,\"category_id\":cat,\n",
    "                                       \"bbox\":[float(x1),float(y1),float(x2-x1),float(y2-y1)],\n",
    "                                       \"score\":float(s)})\n",
    "    if not detections:\n",
    "        return {k:0.0 for k in [\"mAP\",\"AP50\",\"AP75\",\"AP_small\",\"AP_medium\",\"AP_large\",\n",
    "                                \"AR1\",\"AR10\",\"AR100\",\"AR_small\",\"AR_medium\",\"AR_large\"]} | \\\n",
    "               {\"AP_per_class\":{}, \"detailed_metrics\":{}, \"detection_count\":0}\n",
    "\n",
    "    coco_dt = coco_gt.loadRes(detections)\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, iouType=\"bbox\")\n",
    "    coco_eval.params.iouThrs = np.array([0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95])\n",
    "    coco_eval.params.maxDets = [1,10,100]\n",
    "    coco_eval.evaluate(); coco_eval.accumulate(); coco_eval.summarize()\n",
    "    stats = coco_eval.stats\n",
    "\n",
    "    precisions = coco_eval.eval[\"precision\"]\n",
    "    K = precisions.shape[2]\n",
    "    ap_per_class = []\n",
    "    for k in range(K):\n",
    "        p = precisions[:,:,k,0,2]\n",
    "        p = p[p>-1]\n",
    "        ap_per_class.append(np.mean(p) if p.size else float(\"nan\"))\n",
    "    names = [c[\"name\"] for c in coco_gt.loadCats(coco_gt.getCatIds())]\n",
    "    per_class = dict(zip(names, ap_per_class))\n",
    "\n",
    "    recall = coco_eval.eval[\"recall\"]\n",
    "    ar_dets = []\n",
    "    for mdi, md in enumerate([1,10,100]):\n",
    "        r = recall[:,:,:,mdi]; r = r[r>-1]\n",
    "        ar_dets.append(np.mean(r) if r.size else 0.0)\n",
    "    # stats layout: [AP, AP50, AP75, APS, APM, APL, AR1, AR10, AR100, ARS, ARM, ARL]\n",
    "    return {\n",
    "        \"mAP\": stats[0], \"AP50\": stats[1], \"AP75\": stats[2],\n",
    "        \"AP_small\": stats[3], \"AP_medium\": stats[4], \"AP_large\": stats[5],\n",
    "        \"AR1\": stats[6], \"AR10\": stats[7], \"AR100\": stats[8],\n",
    "        \"AR_small\": stats[9], \"AR_medium\": stats[10], \"AR_large\": stats[11],\n",
    "        \"AP_per_class\": per_class,\n",
    "        \"detailed_metrics\": {},\n",
    "        \"detection_count\": len(detections),\n",
    "    }\n",
    "\n",
    "class ValidationLogger:\n",
    "    def __init__(self, experiment_name):\n",
    "        self.experiment = experiment_name\n",
    "        self.log_dir = os.path.join(\"/nas.dbms/asera/validation_logs\", experiment_name)\n",
    "        os.makedirs(self.log_dir, exist_ok=True)\n",
    "        self.csv_path = os.path.join(self.log_dir, \"validation_results.csv\")\n",
    "        self._init_csv()\n",
    "    def _init_csv(self):\n",
    "        fields = [\"epoch\",\"timestamp\",\"experiment\",\"mAP\",\"AP50\",\"AP75\",\"AP_small\",\"AP_medium\",\"AP_large\",\n",
    "                  \"AR1\",\"AR10\",\"AR100\",\"AR_small\",\"AR_medium\",\"AR_large\",\"detection_count\"]\n",
    "        with open(self.csv_path,\"w\",newline=\"\") as f:\n",
    "            csv.DictWriter(f, fieldnames=fields).writeheader()\n",
    "    def log(self, epoch, metrics, writer):\n",
    "        fields = [\"epoch\",\"timestamp\",\"experiment\",\"mAP\",\"AP50\",\"AP75\",\"AP_small\",\"AP_medium\",\"AP_large\",\n",
    "                  \"AR1\",\"AR10\",\"AR100\",\"AR_small\",\"AR_medium\",\"AR_large\",\"detection_count\"]\n",
    "        row = {\n",
    "            \"epoch\": epoch, \"timestamp\": datetime.datetime.now().isoformat(), \"experiment\": self.experiment,\n",
    "            **{k: metrics[k] for k in fields if k in metrics}\n",
    "        }\n",
    "        with open(self.csv_path,\"a\",newline=\"\") as f:\n",
    "            csv.DictWriter(f, fieldnames=fields).writerow(row)\n",
    "        # TB scalars\n",
    "        for k,v in metrics.items():\n",
    "            if isinstance(v,(int,float)):\n",
    "                writer.add_scalar(f\"{self.experiment}/Val/{k}\", v, epoch)\n",
    "        # JSON snapshot per epoch\n",
    "        with open(os.path.join(self.log_dir, f\"epoch_{epoch:03d}_results.json\"), \"w\") as f:\n",
    "            json.dump({\"epoch\":epoch,\"timestamp\":row[\"timestamp\"],\"experiment\":self.experiment,\"metrics\":metrics}, f, indent=2)\n",
    "        return metrics\n",
    "\n",
    "# ------------------------------ Complexity/speed -------------------------------\n",
    "def benchmark_inference(model, data_loader, device, max_images=200, warmup_batches=20):\n",
    "    model.eval()\n",
    "    timings = []; counted = 0\n",
    "    with torch.no_grad():\n",
    "        if device.type == \"cuda\":\n",
    "            starter = torch.cuda.Event(enable_timing=True)\n",
    "            ender = torch.cuda.Event(enable_timing=True)\n",
    "            # warmup\n",
    "            for bi,(images,_) in enumerate(data_loader):\n",
    "                _ = model([im.to(device) for im in images])\n",
    "                if bi+1 >= warmup_batches: break\n",
    "            for (images,_) in data_loader:\n",
    "                images = [im.to(device) for im in images]\n",
    "                starter.record(); _ = model(images); ender.record()\n",
    "                torch.cuda.synchronize()\n",
    "                ms_per_img = starter.elapsed_time(ender)/max(len(images),1)\n",
    "                timings.append(ms_per_img); counted += len(images)\n",
    "                if counted >= max_images: break\n",
    "            lat = float(np.mean(timings)) if timings else float(\"nan\")\n",
    "            return {\"latency_ms_per_image\": lat, \"images_per_second\": (1000.0/lat if lat>0 else float(\"nan\"))}\n",
    "        else:\n",
    "            # CPU fallback\n",
    "            for (images,_) in data_loader:\n",
    "                images = [im.to(device) for im in images]\n",
    "                t0 = time.perf_counter(); _ = model(images); dt = time.perf_counter()-t0\n",
    "                timings.append(1000.0*dt/max(len(images),1)); counted += len(images)\n",
    "                if counted >= max_images: break\n",
    "            lat = float(np.mean(timings)) if timings else float(\"nan\")\n",
    "            return {\"latency_ms_per_image\": lat, \"images_per_second\": (1000.0/lat if lat>0 else float(\"nan\"))}\n",
    "\n",
    "def try_flops_params(model, image_size=(3, 800, 1333)):\n",
    "    params_m = sum(p.numel() for p in model.parameters())/1e6\n",
    "    try:\n",
    "        from fvcore.nn import FlopCountAnalysis\n",
    "        m = copy.deepcopy(model).to(\"cpu\").eval()\n",
    "        dummy = torch.zeros(1,*image_size)\n",
    "        flops = FlopCountAnalysis(m, ([dummy],)).total()\n",
    "        return {\"params_M\": float(params_m), \"FLOPs_G\": float(flops)/1e9}\n",
    "    except Exception:\n",
    "        try:\n",
    "            from thop import profile\n",
    "            m = copy.deepcopy(model).to(\"cpu\").eval()\n",
    "            dummy = torch.zeros(1,*image_size)\n",
    "            macs,_ = profile(m, inputs=([dummy],), verbose=False)\n",
    "            return {\"params_M\": float(params_m), \"FLOPs_G\": float(macs)/1e9}\n",
    "        except Exception:\n",
    "            return {\"params_M\": float(params_m), \"FLOPs_G\": None}\n",
    "\n",
    "# ------------------------------ Train (best by mAP) ---------------------------\n",
    "def train_one(experiment_name, train_dataset, val_dataset, train_loader, val_loader, patched_val_ann_file, insert_level):\n",
    "    C = train_dataset.num_classes\n",
    "    model = build_model(C, insert_level).to(device)\n",
    "\n",
    "    # assert isolation: only the block we asked for\n",
    "    has_lgf = any(isinstance(m, StableLGFBlock) for m in model.modules())\n",
    "    has_cbam  = any(isinstance(m, CBAMBlock)       for m in model.modules())\n",
    "    has_se    = any(isinstance(m, SEBlock)          for m in model.modules())\n",
    "    bt = CURRENT_CONFIG.get(\"block_type\",\"none\")\n",
    "    if bt == \"lgf\": assert has_lgf and not has_cbam and not has_se\n",
    "    if bt == \"cbam\":  assert has_cbam  and not has_lgf and not has_se\n",
    "    if bt == \"se\":    assert has_se    and not has_lgf and not has_cbam\n",
    "    if bt == \"none\":  assert not (has_lgf or has_cbam or has_se)\n",
    "\n",
    "    convert_bn_to_gn(model, num_groups=32, convert_frozen=False)\n",
    "\n",
    "    # Warmup freeze: heads + pre-FPN blocks\n",
    "    for p in model.parameters(): p.requires_grad = False\n",
    "    for p in model.head.parameters(): p.requires_grad = True\n",
    "    if hasattr(model.backbone, \"block_fpn_in\"):\n",
    "        for p in model.backbone.block_fpn_in.parameters(): p.requires_grad = True\n",
    "\n",
    "    ema = ModelEMA(model, decay=0.9999, device=device)\n",
    "    val_logger = ValidationLogger(experiment_name)\n",
    "    writer = SummaryWriter(f\"/nas.dbms/asera/NEW-4.1.2/runs/{experiment_name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "\n",
    "    trainable = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(trainable, lr=args.base_lr, momentum=0.9, weight_decay=1e-4)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=args.lr_milestones, gamma=0.1)\n",
    "\n",
    "    best_map = 0.0\n",
    "    best_epoch = -1\n",
    "    best_ckpt = None\n",
    "    unfroze = False\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        if not unfroze and epoch == 5:\n",
    "            for p in model.parameters(): p.requires_grad = True\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=args.base_lr, momentum=0.9, weight_decay=1e-4)\n",
    "            lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=args.lr_milestones, gamma=0.1)\n",
    "            unfroze = True\n",
    "\n",
    "        # warmup\n",
    "        if epoch < args.warmup_epochs:\n",
    "            lr_scale = min(1., float(epoch+1)/args.warmup_epochs)\n",
    "            for g in optimizer.param_groups: g[\"lr\"] = args.base_lr * lr_scale\n",
    "\n",
    "        model.train()\n",
    "        ep_loss = 0.0\n",
    "        prog = tqdm(train_loader, desc=f\"{experiment_name} - Epoch {epoch+1}/{args.epochs}\")\n",
    "        for bi,(images,targets) in enumerate(prog):\n",
    "            images = [im.to(device) for im in images]\n",
    "            targets = [{k:v.to(device) for k,v in t.items()} for t in targets]\n",
    "            if device.type == \"cuda\":\n",
    "                with autocast(**autocast_kwargs):\n",
    "                    loss_dict = model(images, targets)\n",
    "                    loss = sum(loss_dict.values())/args.accum_steps\n",
    "                scaler.scale(loss).backward()\n",
    "                if (bi+1) % args.accum_steps == 0:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "                    scaler.step(optimizer); scaler.update()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                    ema.update(model)\n",
    "                ep_loss += loss.item()*args.accum_steps\n",
    "                prog.set_postfix(loss=loss.item()*args.accum_steps, lr=optimizer.param_groups[0][\"lr\"])\n",
    "            else:\n",
    "                loss_dict = model(images, targets)\n",
    "                loss = sum(loss_dict.values())/args.accum_steps\n",
    "                loss.backward()\n",
    "                if (bi+1) % args.accum_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                    ema.update(model)\n",
    "                ep_loss += loss.item()*args.accum_steps\n",
    "                prog.set_postfix(loss=loss.item()*args.accum_steps, lr=optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        if (epoch+1) % 5 == 0 or epoch == args.epochs-1:\n",
    "            eval_results = validate_model(ema.ema, epoch, writer, experiment_name, val_logger, val_loader, patched_val_ann_file)\n",
    "            spd = benchmark_inference(ema.ema, val_loader, device)\n",
    "            cmp = try_flops_params(ema.ema)\n",
    "            print(\"[SPEED]\", spd, \"[COMPLEXITY]\", cmp)\n",
    "            if eval_results[\"mAP\"] > best_map:  # best-by-mAP (fixes AP_small bias)\n",
    "            # change to AP_small to match the paper\n",
    "            # if eval_results[\"AP_small\"] > best_map_small:\n",
    "                best_map = eval_results[\"mAP\"]\n",
    "                # best_map_small = eval_results[\"AP_small\"]\n",
    "                best_epoch = epoch+1\n",
    "                os.makedirs(\"/nas.dbms/asera/NEW\", exist_ok=True)\n",
    "                best_ckpt = os.path.join(\"/nas.dbms/asera/NEW\",\n",
    "                    f\"BEST_{experiment_name}_epoch_{best_epoch}_map_{best_map:.4f}.pth\")\n",
    "                # best_ckpt_small = os.path.join(\"/nas.dbms/asera/NEW\",\n",
    "                #     f\"BEST_{experiment_name}_epoch_{best_epoch}_ap_small_{best_map_small:.4f}.pth\")\n",
    "                torch.save({\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"ema_state_dict\": ema.ema.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"scaler_state_dict\": (scaler.state_dict() if scaler is not None else None),\n",
    "                    \"best_map\": best_map,\n",
    "                    # \"best_map_small\": best_map_small,\n",
    "                    \"eval_results\": eval_results,\n",
    "                    \"experiment_name\": experiment_name,\n",
    "                    \"config\": CURRENT_CONFIG,\n",
    "                }, best_ckpt)\n",
    "                print(f\"[SAVE] Best {experiment_name} by mAP: {best_map:.4f} @ epoch {best_epoch}\")\n",
    "                # print(f\"[SAVE] Best {experiment_name} by AP_small: {best_map_small:.4f} @ epoch {best_epoch}\")\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "    writer.close()\n",
    "    return best_map, best_epoch, best_ckpt\n",
    "\n",
    "def validate_model(model, epoch, writer, experiment_name, val_logger, val_loader, patched_val_ann_file):\n",
    "    model.eval()\n",
    "    eval_results = coco_evaluation(model, val_loader, patched_val_ann_file, device)\n",
    "    # >>> ADD THIS BLOCK <<<\n",
    "    try:\n",
    "        from lggf_controls_toolkit import append_result\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        append_result(\"results/all_runs.csv\", dict(\n",
    "            exp=experiment_name,\n",
    "            # if you added these as args, theyll be picked up; else pass fixed strings\n",
    "            gate_override=getattr(args, \"gate_override\", \"\"),   # ok if empty\n",
    "            alpha_local=getattr(args, \"alpha_local\", \"\"),       # ok if empty\n",
    "            insert_level=args.insert_level,\n",
    "            seed=args.seed,\n",
    "            mAP=eval_results[\"mAP\"],\n",
    "            AP_small=eval_results[\"AP_small\"],\n",
    "            AP50=eval_results[\"AP50\"],\n",
    "            AP75=eval_results[\"AP75\"],\n",
    "            AR100=eval_results[\"AR100\"],\n",
    "            dets=eval_results.get(\"detection_count\", 0),\n",
    "            ips=0.0,  # you log ips elsewhere; leave 0.0 here or wire in your speed dict\n",
    "        ))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] append_result failed: {e}\")\n",
    "    # <<< END ADD >>>\n",
    "\n",
    "    logged = val_logger.log(epoch, eval_results, writer)\n",
    "    model.train()\n",
    "    return logged\n",
    "\n",
    "class ModelEMA:\n",
    "    def __init__(self, model, decay=0.9999, device=None):\n",
    "        self.ema = copy.deepcopy(model)\n",
    "        self.ema.eval()\n",
    "        self.decay = decay\n",
    "        if device is not None: self.ema.to(device)\n",
    "        for p in self.ema.parameters(): p.requires_grad_(False)\n",
    "    def update(self, model):\n",
    "        with torch.no_grad():\n",
    "            msd = model.state_dict()\n",
    "            for k,v in self.ema.state_dict().items():\n",
    "                if not v.dtype.is_floating_point: continue\n",
    "                src = msd.get(k); \n",
    "                if src is None: continue\n",
    "                v.copy_(v * self.decay + src.to(v.device) * (1. - self.decay))\n",
    "\n",
    "# ------------------------------- Aggregation (4) -------------------------------\n",
    "def best_by_map(run_dir):\n",
    "    files = sorted(glob(os.path.join(run_dir, \"epoch_*_results.json\")))\n",
    "    best = None\n",
    "    for f in files:\n",
    "        d = json.load(open(f))\n",
    "        m = d[\"metrics\"]\n",
    "        row = {\"epoch\": d[\"epoch\"], **{k:m[k] for k in [\"mAP\",\"AP50\",\"AP75\",\"AP_small\",\"AP_medium\",\"AP_large\"]}}\n",
    "        if best is None or row[\"mAP\"] > best[\"mAP\"]:\n",
    "            best = row\n",
    "    return best\n",
    "\n",
    "def best_by_apsmall(run_dir):\n",
    "    files = sorted(glob(os.path.join(run_dir, \"epoch_*_results.json\")))\n",
    "    best = None\n",
    "    for f in files:\n",
    "        d = json.load(open(f))\n",
    "        m = d[\"metrics\"]\n",
    "        row = {\"epoch\": d[\"epoch\"], **{k:m[k] for k in [\"AP_small\",\"AP_medium\",\"AP_large\",\"AP50\",\"AP75\",\"mAP\",\"AR1\",\"AR10\",\"AR100\",\"AR_small\",\"AR_medium\",\"AR_large\"]}}\n",
    "        if best is None or row[\"AP_small\"] > best[\"AP_small\"]:\n",
    "            best = row\n",
    "    return best\n",
    "\n",
    "def aggregate_group(group_name, run_names):\n",
    "    rows = []\n",
    "    for r in run_names:\n",
    "        path = os.path.join(\"/nas.dbms/asera/validation_logs\", r)\n",
    "        if not os.path.isdir(path):\n",
    "            print(f\"[SKIP] missing {path}\")\n",
    "            continue\n",
    "        # rows.append(best_by_map(path))\n",
    "        rows.append(best_by_apsmall(path))\n",
    "    if not rows:\n",
    "        print(f\"[EMPTY] {group_name}\")\n",
    "        return\n",
    "    def ms(key):\n",
    "        vals = np.array([row[key] for row in rows], dtype=float)\n",
    "        return vals.mean(), vals.std(ddof=1) if len(vals) > 1 else 0.0\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(group_name)\n",
    "    for k in [\"AP_small\",\"AP_medium\",\"AP_large\",\"AP50\",\"AP75\",\"mAP\",\"AR1\",\"AR10\",\"AR100\",\"AR_small\",\"AR_medium\",\"AR_large\"]:\n",
    "        mu, sd = ms(k)\n",
    "        print(f\"{k}: {mu:.3f}  {sd:.3f}  (epochs {[row['epoch'] for row in rows]})\")\n",
    "\n",
    "# ------------------------------- Grid runner (2) -------------------------------\n",
    "def run_grid_subprocess(modes, datasets, levels, seeds):\n",
    "    this = os.path.abspath(sys.argv[0])\n",
    "    py = sys.executable\n",
    "    for ds in datasets:\n",
    "        for lvl in levels:\n",
    "            for mode in modes:\n",
    "                for s in seeds:\n",
    "                    exp = f\"{ds}_{lvl}_{mode}_s{s}\"\n",
    "                    cmd = [\n",
    "                        py, \"-u\", this,\n",
    "                        \"--mode\", mode,\n",
    "                        \"--dataset\", ds,\n",
    "                        \"--insert-level\", lvl,\n",
    "                        \"--seed\", str(s),\n",
    "                        \"--exp-name\", exp,\n",
    "                        \"--epochs\", str(args.epochs),\n",
    "                        \"--batch-size\", str(args.batch_size),\n",
    "                        \"--accum-steps\", str(args.accum_steps),\n",
    "                        \"--num-workers\", str(args.num_workers),\n",
    "                        \"--prefetch-factor\", str(args.prefetch_factor),\n",
    "                    ]\n",
    "                    print(\"[RUN]\", \" \".join(cmd))\n",
    "                    subprocess.run(cmd, check=True)\n",
    "\n",
    "def run_grid_inprocess(modes, datasets, levels, seeds):\n",
    "    # Clean in-process loop that rebuilds loaders for each seed/dataset (covers item 0)\n",
    "    for ds in datasets:\n",
    "        for lvl in levels:\n",
    "            for mode in modes:\n",
    "                global CURRENT_CONFIG\n",
    "                CURRENT_CONFIG = CONFIG_MAP[mode]\n",
    "                for s in seeds:\n",
    "                    exp = f\"{ds}_{lvl}_{mode}_s{s}\"\n",
    "                    overrides = dict(train_img=args.train_img, train_ann=args.train_ann,\n",
    "                                     val_img=args.val_img, val_ann=args.val_ann)\n",
    "                    train_dataset, val_dataset, train_loader, val_loader, patched_val = \\\n",
    "                        build_datasets_and_loaders(s, ds, overrides)\n",
    "                    print(f\"\\n=== {exp} ===\")\n",
    "                    best_map, best_epoch, best_ckpt = train_one(exp, train_dataset, val_dataset,\n",
    "                                                                train_loader, val_loader, patched_val, lvl)\n",
    "                    print(f\"[DONE] {exp}: best mAP {best_map:.4f} @ {best_epoch}; ckpt={best_ckpt}\")\n",
    "\n",
    "# ----------------------------------- main -------------------------------------\n",
    "def main():\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Mode={args.mode} Insert={args.insert_level} Dataset={args.dataset} Seed={args.seed}\")\n",
    "\n",
    "    # Grid\n",
    "    if args.run_grid:\n",
    "        modes = args.grid_modes or [\"baseline\",\"se\",\"cbam\",\"lgf_gated_spatial\"]\n",
    "        datasets = args.grid_datasets or [\"coco_nw\"]\n",
    "        levels = args.grid_levels or [\"C3\"]\n",
    "        seeds  = args.grid_seeds or [42,1337,2025]\n",
    "        if args.subprocess and hasattr(sys, \"argv\") and sys.argv[0].endswith(\".py\"):\n",
    "            run_grid_subprocess(modes, datasets, levels, seeds)\n",
    "        else:\n",
    "            run_grid_inprocess(modes, datasets, levels, seeds)\n",
    "        return\n",
    "\n",
    "    # Single run\n",
    "    overrides = dict(train_img=args.train_img, train_ann=args.train_ann,\n",
    "                     val_img=args.val_img, val_ann=args.val_ann)\n",
    "    train_dataset, val_dataset, train_loader, val_loader, patched_val = \\\n",
    "        build_datasets_and_loaders(args.seed, args.dataset, overrides)\n",
    "\n",
    "    global CURRENT_CONFIG\n",
    "    exp = args.exp_name or f\"{args.dataset}_{args.insert_level}_{args.mode}_s{args.seed}\"\n",
    "    print(f\"Training on {len(train_dataset)} images; validating on {len(val_dataset)} images\")\n",
    "    print(f\"Batch={args.batch_size}, Accum={args.accum_steps}, LR={args.base_lr}, Epochs={args.epochs}\")\n",
    "    print(f\"Training on {len(train_dataset)} images; validating on {len(val_dataset)} images\")\n",
    "    print(f\"Batch={args.batch-size if hasattr(args,'batch-size') else args.batch_size}, Accum={args.accum_steps}, LR={args.base_lr}, Epochs={args.epochs}\")\n",
    "\n",
    "    best_map, best_epoch, best_ckpt = train_one(exp, train_dataset, val_dataset,\n",
    "                                                train_loader, val_loader, patched_val, args.insert_level)\n",
    "    print(f\"[RESULT] {exp}: best mAP {best_map:.4f} @ epoch {best_epoch}; ckpt={best_ckpt}\")\n",
    "\n",
    "    # Aggregate if asked\n",
    "    if args.aggregate:\n",
    "        agg_datasets = args.agg_datasets or [args.dataset]\n",
    "        agg_levels   = args.agg_levels or [args.insert_level]\n",
    "        agg_modes    = args.agg_modes  or [args.mode]\n",
    "        agg_seeds    = args.agg_seeds\n",
    "        for ds in agg_datasets:\n",
    "            for lvl in agg_levels:\n",
    "                for mode in agg_modes:\n",
    "                    runs = [f\"{ds}_{lvl}_{mode}_s{s}\" for s in agg_seeds]\n",
    "                    aggregate_group(f\"Aggregate {ds} {lvl} {mode}\", runs)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3760f136",
   "metadata": {},
   "source": [
    "TRAINING & EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 seeds, all models (COCONW, COCO-Weather, ACDC at C3):\n",
    "run_grid_inprocess([\"baseline\",\"se\",\"cbam\",\"lgf_gated\",\"lgf_softmax\",\"lgf_sum\",\"lgf_gated_spatial\"], [\"coco_nw\"], [\"coco_nw\",\"coco_weather\",\"acdc\"], [42, 1337, 2025])\n",
    "\n",
    "# Or you can run specific configurations, e.g.:\n",
    "# # 3 seeds, LGGF gatedspatial (COCONW, C3):\n",
    "# run_grid_inprocess([\"lgf_gated_spatial\"], [\"coco_nw\"], [\"C3\"], [2025])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d6b02d",
   "metadata": {},
   "source": [
    "3-SEEDS SUMMARY REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BY MODEL AGGREGATIONS\n",
    "#=============BASELINE AGGREGATIONS =============#\n",
    "# Baseline on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_baseline_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"Baseline C3 on COCO-NW\", runs)\n",
    "\n",
    "# Baseline on COCOWeather C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_baseline_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"Baseline C3 on COCO-Weather\", runs)\n",
    "\n",
    "# Baseline on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_baseline_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"Baseline C3 on ACDC\", runs)\n",
    "\n",
    "#=============LGGF GATED SPATIAL AGGREGATIONS =============#\n",
    "# LGGF gated_spatial on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_lgf_gated_spatial_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF gated_spatial C3 on COCO-NW\", runs)\n",
    "\n",
    "# LGGF gated_spatial on COCO_WEATHER C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_lgf_gated_spatial_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF gated_spatial C3 on COCO-Weather\", runs)\n",
    "\n",
    "# LGGF gated_spatial on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_lgf_gated_spatial_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF gated_spatial C3 on ACDC\", runs)\n",
    "\n",
    "#=============LGGF SUM SPATIAL AGGREGATIONS =============#\n",
    "# LGGF sum on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_lgf_sum_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF sum C3 on COCO-NW\", runs)\n",
    "\n",
    "# LGGF sum on COCOWeather C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_lgf_sum_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF sum C3 on COCO-Weather\", runs)\n",
    "\n",
    "# LGGF sum on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_lgf_sum_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF sum C3 on ACDC\", runs)\n",
    "\n",
    "#=============LGGF SOFTMAX AGGREGATIONS =============#\n",
    "# LGGF softmax on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_lgf_softmax_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF softmax C3 on COCO-NW\", runs)\n",
    "\n",
    "# LGGF softmax on COCOWeather C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_lgf_softmax_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF softmax C3 on COCO-Weather\", runs)\n",
    "\n",
    "# LGGF softmax on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_lgf_softmax_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF softmax C3 on ACDC\", runs)\n",
    "\n",
    "#=============LGGF GATED AGGREGATIONS =============#\n",
    "# LGGF gated on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_lgf_gated_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF gated C3 on COCO-NW\", runs)\n",
    "\n",
    "# LGGF gated on COCOWeather C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_lgf_gated_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF gated C3 on COCO-Weather\", runs)\n",
    "\n",
    "# LGGF gated on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_lgf_gated_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF gated C3 on ACDC\", runs)\n",
    "\n",
    "#=============CBAM AGGREGATIONS =============#\n",
    "# CBAM on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_cbam_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"CBAM C3 on COCO-NW\", runs)\n",
    "\n",
    "# CBAM on COCOWeather C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_cbam_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"CBAM C3 on COCO-Weather\", runs)\n",
    "\n",
    "# CBAM on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_cbam_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"CBAM C3 on ACDC\", runs)\n",
    "\n",
    "#=============SE AGGREGATIONS =============#\n",
    "# SE on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_se_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"SE C3 on COCO-NW\", runs)\n",
    "\n",
    "# SE on Weather C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_se_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"SE C3 on COCO-Weather\", runs)\n",
    "\n",
    "# SE on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_se_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"SE C3 on ACDC\", runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc0a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BY DATASET AGGREGATIONS\n",
    "#=============COCO-NW AGGREGATIONS =============#\n",
    "# Baseline on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_baseline_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"Baseline C3 on COCO-NW\", runs)\n",
    "\n",
    "# CBAM on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_cbam_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"CBAM C3 on COCO-NW\", runs)\n",
    "\n",
    "# SE on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_se_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"SE C3 on COCO-NW\", runs)\n",
    "\n",
    "# LGGF gated_spatial on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_lgf_gated_spatial_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF gated_spatial C3 on COCO-NW\", runs)\n",
    "\n",
    "# LGGF sum on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_lgf_sum_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF sum C3 on COCO-NW\", runs)\n",
    "\n",
    "# LGGF softmax on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_lgf_softmax_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF softmax C3 on COCO-NW\", runs)\n",
    "\n",
    "# LGGF gated on COCONW C3 over the 3 seeds\n",
    "runs = [f\"coco_nw_C3_lgf_gated_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF gated C3 on COCO-NW\", runs)\n",
    "\n",
    "\n",
    "\n",
    "#=============COCO-WEATHER AGGREGATIONS =============#\n",
    "\n",
    "# Baseline on COCOWeather C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_baseline_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"Baseline C3 on COCO-Weather\", runs)\n",
    "\n",
    "# CBAM on COCOWeather C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_cbam_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"CBAM C3 on COCO-Weather\", runs)\n",
    "\n",
    "# SE on Weather C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_se_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"SE C3 on COCO-Weather\", runs)\n",
    "\n",
    "# LGGF gated_spatial on COCO_WEATHER C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_lgf_gated_spatial_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF gated_spatial C3 on COCO-Weather\", runs)\n",
    "\n",
    "# LGGF sum on COCOWeather C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_lgf_sum_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF sum C3 on COCO-Weather\", runs)\n",
    "\n",
    "# LGGF softmax on COCOWeather C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_lgf_softmax_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF softmax C3 on COCO-Weather\", runs)\n",
    "\n",
    "# LGGF gated on COCOWeather C3 over the 3 seeds\n",
    "runs = [f\"coco_weather_C3_lgf_gated_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF gated C3 on COCO-Weather\", runs)\n",
    "\n",
    "\n",
    "\n",
    "#=============ACDC AGGREGATIONS =============#\n",
    "\n",
    "# Baseline on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_baseline_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"Baseline C3 on ACDC\", runs)\n",
    "\n",
    "# CBAM on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_cbam_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"CBAM C3 on ACDC\", runs)\n",
    "\n",
    "# SE on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_se_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"SE C3 on ACDC\", runs)\n",
    "\n",
    "# LGGF gated_spatial on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_lgf_gated_spatial_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF gated_spatial C3 on ACDC\", runs)\n",
    "\n",
    "# LGGF sum on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_lgf_sum_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF sum C3 on ACDC\", runs)\n",
    "\n",
    "# LGGF softmax on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_lgf_softmax_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF softmax C3 on ACDC\", runs)\n",
    "\n",
    "# LGGF gated on ACDC C3 over the 3 seeds\n",
    "runs = [f\"acdc_C3_lgf_gated_s{s}\" for s in [42,1337,2025]]\n",
    "aggregate_group(\"LGGF gated C3 on ACDC\", runs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b68248",
   "metadata": {},
   "source": [
    "POST EVALUATION FROM A SAVED TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f534f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== EVAL-ONLY CELL ====\n",
    "import json, torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def _find_key(sd, suffix):\n",
    "    for k in sd.keys():\n",
    "        if k.endswith(suffix):\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "def evaluate_checkpoint(\n",
    "    ckpt_path,\n",
    "    dataset=\"coco_weather\",  # coco_nw | coco_weather | acdc | custom,\n",
    "    use_ema=True,\n",
    "    insert_level=None,   # C3 | C4 | C5 | None for auto\n",
    "    val_img=None,\n",
    "    val_ann=None,\n",
    "    batch_size=4,\n",
    "    num_workers=8,\n",
    "    prefetch_factor=4,\n",
    "    seed=42,\n",
    "    speed=True,\n",
    "    complexity=False,\n",
    "    max_images_speed=200\n",
    "):\n",
    "    set_seed(seed)\n",
    "    dev = device\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=dev)\n",
    "    sd = ckpt.get(\"ema_state_dict\") if use_ema and (\"ema_state_dict\" in ckpt) else ckpt[\"model_state_dict\"]\n",
    "\n",
    "    # Strip DDP \"module.\" prefix if present\n",
    "    if any(k.startswith(\"module.\") for k in sd.keys()):\n",
    "        sd = {k[7:]: v for k, v in sd.items()}\n",
    "\n",
    "    # Build validation dataset/loader first to know class count\n",
    "    if dataset == \"custom\":\n",
    "        if not (val_img and val_ann):\n",
    "            raise ValueError(\"dataset='custom' requires val_img and val_ann\")\n",
    "        va_img, va_ann = val_img, patch_annotations_once(val_ann)\n",
    "    else:\n",
    "        _, _, va_img, raw_va_ann = select_dataset_by_name(dataset)\n",
    "        va_ann = patch_annotations_once(raw_va_ann)\n",
    "\n",
    "    val_dataset = COCODataset(va_img, va_ann, transforms=get_transform(train=False), train=False)\n",
    "    dataset_k = val_dataset.num_classes\n",
    "\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    common = dict(collate_fn=collate_fn, worker_init_fn=worker_init_fn, pin_memory=True, generator=g)\n",
    "    if num_workers > 0:\n",
    "        common.update(num_workers=num_workers, persistent_workers=True, prefetch_factor=prefetch_factor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False, **common)\n",
    "\n",
    "    # Restore trained config if present\n",
    "    global CURRENT_CONFIG\n",
    "    if \"config\" in ckpt:\n",
    "        CURRENT_CONFIG = ckpt[\"config\"]\n",
    "\n",
    "    # Infer anchors-per-location and class count\n",
    "    cls_w_key = _find_key(sd, \"classification_head.cls_logits.weight\")\n",
    "    if cls_w_key is None:\n",
    "        raise KeyError(\"Missing classification_head.cls_logits.weight in checkpoint\")\n",
    "\n",
    "    out_ch = sd[cls_w_key].shape[0]  # A * K\n",
    "    if out_ch % dataset_k == 0:\n",
    "        a_per_loc = out_ch // dataset_k\n",
    "        k_trained = dataset_k\n",
    "    else:\n",
    "        reg_w_key = _find_key(sd, \"regression_head.bbox_regression.weight\")\n",
    "        if reg_w_key is not None:\n",
    "            a_per_loc = sd[reg_w_key].shape[0] // 4\n",
    "            k_trained = out_ch // a_per_loc\n",
    "        else:\n",
    "            a_per_loc = 9\n",
    "            k_trained = out_ch // a_per_loc\n",
    "        if k_trained != dataset_k:\n",
    "            raise RuntimeError(\n",
    "                f\"Class count mismatch. ckpt K={k_trained}, dataset K={dataset_k} \"\n",
    "                f\"(cls out={out_ch}, anchors per loc={a_per_loc})\"\n",
    "            )\n",
    "\n",
    "    # Decide insert level\n",
    "    def _parse_lvl_from_name(name):\n",
    "        for lvl in [\"C3\", \"C4\", \"C5\"]:\n",
    "            if f\"_{lvl}_\" in name or name.endswith(f\"_{lvl}\") or name.startswith(f\"{lvl}_\"):\n",
    "                return lvl\n",
    "        return None\n",
    "\n",
    "    if insert_level is None:\n",
    "        name_guess = str(ckpt.get(\"experiment_name\", \"\"))\n",
    "        parsed = _parse_lvl_from_name(name_guess)\n",
    "        candidates = [parsed] + [l for l in [\"C3\",\"C4\",\"C5\"] if l != parsed] if parsed else [\"C3\",\"C4\",\"C5\"]\n",
    "    else:\n",
    "        candidates = [insert_level]\n",
    "\n",
    "    # Helper for scoring IncompatibleKeys without error_msgs\n",
    "    def _score_incompat(res):\n",
    "        mk = getattr(res, \"missing_keys\", [])\n",
    "        uk = getattr(res, \"unexpected_keys\", [])\n",
    "        return len(mk) + len(uk)\n",
    "\n",
    "    # Rebuild model and load weights, pick best matching level\n",
    "    best_model = None\n",
    "    best_level = None\n",
    "    best_score = None\n",
    "    for lvl in candidates:\n",
    "        m = build_model(k_trained, lvl).to(dev)\n",
    "        res = m.load_state_dict(sd, strict=False)\n",
    "        score = _score_incompat(res)\n",
    "        if best_score is None or score < best_score:\n",
    "            best_model = m\n",
    "            best_level = lvl\n",
    "            best_score = score\n",
    "        if score == 0:\n",
    "            break\n",
    "\n",
    "    model = best_model\n",
    "    model.eval()\n",
    "\n",
    "    # COCO evaluation\n",
    "    with torch.no_grad():\n",
    "        metrics = coco_evaluation(model, val_loader, va_ann, dev)\n",
    "\n",
    "    out = {\n",
    "        \"checkpoint\": ckpt_path,\n",
    "        \"experiment_name\": ckpt.get(\"experiment_name\"),\n",
    "        \"block_type\": CURRENT_CONFIG.get(\"block_type\", \"none\"),\n",
    "        \"gating_type\": CURRENT_CONFIG.get(\"gating_type\", \"none\"),\n",
    "        \"insert_level\": best_level,\n",
    "        \"dataset\": dataset,\n",
    "        \"num_classes\": k_trained,\n",
    "        **metrics\n",
    "    }\n",
    "\n",
    "    if speed:\n",
    "        out.update(benchmark_inference(model, val_loader, dev, max_images=max_images_speed))\n",
    "    if complexity:\n",
    "        out.update(try_flops_params(model))\n",
    "\n",
    "    print(json.dumps(out, indent=2))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4609aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single checkpoint on a defined dataset\n",
    "_ = evaluate_checkpoint(\n",
    "    \"NEW/4.1.2/BEST_coco_nw_C3_cbam_s42_epoch_80_map_0.3422_apsmall_0.2223.pth\",\n",
    "    dataset=\"coco_nw\",\n",
    "    use_ema=True,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    prefetch_factor=4,\n",
    "    speed=True,\n",
    "    complexity=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b4618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a few checkpoints in a folder\n",
    "from glob import glob\n",
    "ckpts = sorted(glob(\"/nas.dbms/asera/NEW/4.1.2/BEST_coco_nw_C3_lgf_gated_spatial_s*_epoch_*_map_*.pth\"))\n",
    "results = [evaluate_checkpoint(p, dataset=\"coco_nw\", use_ema=True, speed=False) for p in ckpts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset, val-only paths OPTIONAL\n",
    "_ = evaluate_checkpoint(\n",
    "    \"/nas.dbms/asera/NEW/BEST_custom_C4_cbam_s2025_epoch_080_map_0.3871.pth\",\n",
    "    dataset=\"custom\",\n",
    "    val_img=\"/abs/path/to/your/val/images\",\n",
    "    val_ann=\"/abs/path/to/your/val/annotations.json\",\n",
    "    use_ema=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d82fe",
   "metadata": {},
   "source": [
    "CONTROL VARIANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e50a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CONTROL VARIANTS EVAL CELL ====\n",
    "# Runs \"native\", \"uniform\", \"global_mean\", \"shuffle\", \"swap_in_batch\" on a saved lgf model.\n",
    "\n",
    "import types, json, torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _build_val_loader(dataset_code, seed=42, batch_size=4, num_workers=8, prefetch_factor=4,\n",
    "                      val_img=None, val_ann=None):\n",
    "    if dataset_code == \"custom\":\n",
    "        if not (val_img and val_ann):\n",
    "            raise ValueError(\"dataset='custom' needs val_img and val_ann\")\n",
    "        va_img, va_ann = val_img, patch_annotations_once(val_ann)\n",
    "    else:\n",
    "        _, _, va_img, raw_va_ann = select_dataset_by_name(dataset_code)\n",
    "        va_ann = patch_annotations_once(raw_va_ann)\n",
    "\n",
    "    val_dataset = COCODataset(va_img, va_ann, transforms=get_transform(train=False), train=False)\n",
    "    g = torch.Generator(); g.manual_seed(seed)\n",
    "    common = dict(collate_fn=collate_fn, worker_init_fn=worker_init_fn, pin_memory=True, generator=g)\n",
    "    if num_workers > 0:\n",
    "        common.update(num_workers=num_workers, persistent_workers=True, prefetch_factor=prefetch_factor)\n",
    "    loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False, **common)\n",
    "    return val_dataset, loader, va_ann\n",
    "\n",
    "def _strip_module_prefix(sd):\n",
    "    return {k[7:]: v for k, v in sd.items()} if any(k.startswith(\"module.\") for k in sd) else sd\n",
    "\n",
    "def _infer_insert_level_from_name(name):\n",
    "    for lvl in [\"C3\",\"C4\",\"C5\"]:\n",
    "        if f\"_{lvl}_\" in name or name.endswith(f\"_{lvl}\") or name.startswith(f\"{lvl}_\"):\n",
    "            return lvl\n",
    "    return None\n",
    "\n",
    "def _native_spatial_weights(block, x):\n",
    "    # Compute native gated_spatial weights wL, wG using the block's own layers\n",
    "    h = F.relu(block.gate_reduce(x), inplace=True)\n",
    "    logits = block.gate_expand(h)\n",
    "    logits = block.gate_norm(logits)\n",
    "    with torch.cuda.amp.autocast(enabled=False):\n",
    "        logits32 = logits.float().clamp_(-15, 15)\n",
    "        tau = F.softplus(block.temperature.float()) + 1e-3\n",
    "        w = torch.sigmoid(logits32 / tau)\n",
    "    N, twoC, H, W = w.shape\n",
    "    C = twoC // 2\n",
    "    w = w.to(dtype=x.dtype).view(N, 2, C, H, W)\n",
    "    return w[:,0], w[:,1]  # wL, wG\n",
    "\n",
    "# def _patch_gate_override(model, override=\"native\", gate_seed=None, gamma_mult=None):\n",
    "#     \"\"\"\n",
    "#     Monkey-patch StableLGFBlock.forward to enforce control behaviors during eval.\n",
    "#     Supports only 'lgf' blocks. Leaves others untouched.\n",
    "#     \"\"\"\n",
    "#     rng = torch.Generator(device=device) if device.type == \"cuda\" else torch.Generator()\n",
    "#     if gate_seed is not None:\n",
    "#         rng.manual_seed(int(gate_seed))\n",
    "\n",
    "#     for m in model.modules():\n",
    "#         if not isinstance(m, StableLGFBlock):\n",
    "#             continue\n",
    "\n",
    "#         # option to scale gamma consistently across all LGGF blocks\n",
    "#         if gamma_mult is not None:\n",
    "#             with torch.no_grad():\n",
    "#                 m.gamma.fill_(float(gamma_mult))\n",
    "\n",
    "#         if override == \"native\":\n",
    "#             continue  # no patching needed\n",
    "\n",
    "#         # keep original forward for restoration if you want later\n",
    "#         if not hasattr(m, \"_orig_forward\"):\n",
    "#             m._orig_forward = m.forward\n",
    "\n",
    "#         def wrapped_forward(self, x, *_args, **_kwargs):\n",
    "#             # Recompute L and G branches explicitly\n",
    "#             feats = []\n",
    "#             L = self.local(x) if self.local is not None else None\n",
    "#             if L is not None: feats.append(L)\n",
    "#             G = None\n",
    "#             if self.global_branch is not None:\n",
    "#                 g = self.global_branch(x)\n",
    "#                 G = g.expand_as(x)\n",
    "#                 feats.append(G)\n",
    "\n",
    "#             if len(feats) == 1:\n",
    "#                 out_core = feats[0]\n",
    "#                 wL = torch.ones_like(out_core); wG = torch.zeros_like(out_core)\n",
    "#             else:\n",
    "#                 if self.gating_type == \"gated_spatial\":\n",
    "#                     # Base weights from native computation\n",
    "#                     wL_native, wG_native = _native_spatial_weights(self, x)\n",
    "\n",
    "#                     if override == \"uniform\":\n",
    "#                         wL = torch.ones_like(wL_native) * 0.5\n",
    "#                         wG = torch.ones_like(wG_native) * 0.5\n",
    "#                     elif override == \"global_mean\":\n",
    "#                         # Collapse spatial to per-channel constants, broadcast back\n",
    "#                         wL_mean = wL_native.mean(dim=(2,3), keepdim=True)\n",
    "#                         wG_mean = wG_native.mean(dim=(2,3), keepdim=True)\n",
    "#                         wL = wL_mean.expand_as(wL_native)\n",
    "#                         wG = wG_mean.expand_as(wG_native)\n",
    "#                     elif override == \"shuffle\":\n",
    "#                         # Shuffle gates across images in batch, same permutation for L and G\n",
    "#                         N = wL_native.shape[0]\n",
    "#                         if N > 1:\n",
    "#                             perm = torch.randperm(N, generator=rng, device=wL_native.device)\n",
    "#                             wL = wL_native[perm]\n",
    "#                             wG = wG_native[perm]\n",
    "#                         else:\n",
    "#                             wL, wG = wL_native, wG_native\n",
    "#                     elif override == \"swap_in_batch\":\n",
    "#                         # Rotate gates within batch by +1\n",
    "#                         N = wL_native.shape[0]\n",
    "#                         if N > 1:\n",
    "#                             wL = torch.roll(wL_native, shifts=1, dims=0)\n",
    "#                             wG = torch.roll(wG_native, shifts=1, dims=0)\n",
    "#                         else:\n",
    "#                             wL, wG = wL_native, wG_native\n",
    "#                     else:\n",
    "#                         # Fallback to native if unknown label\n",
    "#                         wL, wG = wL_native, wG_native\n",
    "\n",
    "#                     # Fuse\n",
    "#                     # L, G are [N,C,H,W]; wL,wG are [N,C,H,W]\n",
    "#                     out_core = wL * L + wG * G\n",
    "#                 else:\n",
    "#                     # For non-spatial gate modes, emulate simple controls\n",
    "#                     if override in (\"uniform\", \"global_mean\"):\n",
    "#                         out_core = 0.5 * L + 0.5 * G\n",
    "#                     elif override in (\"shuffle\", \"swap_in_batch\"):\n",
    "#                         # emulate by shuffling G across batch only\n",
    "#                         N = G.shape[0]\n",
    "#                         if N > 1:\n",
    "#                             perm = torch.randperm(N, generator=rng, device=G.device) if override==\"shuffle\" else torch.roll(torch.arange(N, device=G.device), shifts=1)\n",
    "#                             out_core = 0.5 * L + 0.5 * G[perm]\n",
    "#                         else:\n",
    "#                             out_core = 0.5 * L + 0.5 * G\n",
    "#                     else:\n",
    "#                         out_core = 0.5 * L + 0.5 * G\n",
    "\n",
    "#             return x + self.gamma * out_core\n",
    "\n",
    "        # m.forward = types.MethodType(wrapped_forward, m)\n",
    "import types, torch\n",
    "\n",
    "def _patch_gate_override(\n",
    "    model,\n",
    "    override=\"native\",\n",
    "    *,\n",
    "    gate_seed=None,\n",
    "    gamma_mult=None,\n",
    "    temp_mult=None,\n",
    "    temp_set=None,\n",
    "    alpha_local=None,            #  for the sweep: scales local gates before renorm\n",
    "    global_mean_mode=\"scalar\"    # \"scalar\" = per-image scalar, \"channel\" = per-channel\n",
    "):\n",
    "    \"\"\"\n",
    "    override options:\n",
    "      \"native\"               learned gate maps as-is\n",
    "      \"global_mean\"          per-image scalar gate (paper); set global_mean_mode to \"channel\" to match old per-channel behavior\n",
    "      \"uniform\"              wL=wG=0.5\n",
    "      \"shuffle\"              shuffle gates across images AND channels\n",
    "      \"swap_lg\"              swap learned local/global gate assignments\n",
    "      \"no_module\"            remove module, return x\n",
    "      \"only_local\"           wL=1, wG=0\n",
    "      \"only_global\"          wL=0, wG=1\n",
    "    Optional knobs:\n",
    "      alpha_local            -sweep; multiply local gates by  then renormalize with global\n",
    "      temp_mult/temp_set     gate temperature tweaks\n",
    "      gamma_mult             multiplicatively scale learned residual  (do not overwrite)\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    rng = torch.Generator(device=device)\n",
    "    if gate_seed is not None:\n",
    "        rng.manual_seed(int(gate_seed))\n",
    "\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__ != \"StableLGFBlock\":\n",
    "            continue\n",
    "\n",
    "        # keep learned gamma, allow multiplicative scaling only\n",
    "        if gamma_mult is not None:\n",
    "            with torch.no_grad():\n",
    "                m.gamma.mul_(float(gamma_mult))\n",
    "\n",
    "        # optional temperature probe\n",
    "        if hasattr(m, \"temperature\"):\n",
    "            with torch.no_grad():\n",
    "                if temp_mult is not None:\n",
    "                    m.temperature.mul_(float(temp_mult))\n",
    "                if temp_set is not None:\n",
    "                    m.temperature.fill_(float(temp_set))\n",
    "\n",
    "        if override == \"native\" and alpha_local is None:\n",
    "            continue\n",
    "\n",
    "        if not hasattr(m, \"_orig_forward\"):\n",
    "            m._orig_forward = m.forward\n",
    "\n",
    "        def wrapped_forward(self, x, *a, **k):\n",
    "            # must be the spatial gate for these controls to mean anything\n",
    "            if getattr(self, \"gating_type\", None) != \"gated_spatial\":\n",
    "                # fall back to original forward to avoid misleading results\n",
    "                return self._orig_forward(x, *a, **k) if hasattr(self, \"_orig_forward\") else super(type(self), self).forward(x, *a, **k)\n",
    "\n",
    "            # compute branches\n",
    "            L = self.local(x) if getattr(self, \"local\", None) is not None else None\n",
    "            G = None\n",
    "            if getattr(self, \"global_branch\", None) is not None:\n",
    "                g = self.global_branch(x)\n",
    "                G = g.expand_as(L if L is not None else g)\n",
    "\n",
    "            # kill the whole module if asked\n",
    "            if override == \"no_module\":\n",
    "                return x\n",
    "\n",
    "            # degenerate cases\n",
    "            if L is None or G is None:\n",
    "                out_core = L if L is not None else G\n",
    "                return x + self.gamma * out_core\n",
    "\n",
    "            # native spatial gates\n",
    "            wL_native, wG_native = _native_spatial_weights(self, x)  # assumes these sum to ~1\n",
    "\n",
    "            # build wL, wG\n",
    "            wL, wG = wL_native, wG_native\n",
    "\n",
    "            if override == \"only_local\":\n",
    "                wL = torch.ones_like(wL_native, 1)\n",
    "                wG = torch.zeros_like(wG_native, 0)\n",
    "\n",
    "            elif override == \"only_global\":\n",
    "                wL = torch.zeros_like(wL_native, 0)\n",
    "                wG = torch.ones_like(wG_native, 1)\n",
    "\n",
    "            elif override == \"uniform\":\n",
    "                wL = torch.full_like(wL_native, 0.5)\n",
    "                wG = torch.full_like(wG_native, 0.5)\n",
    "\n",
    "            elif override == \"global_mean\":\n",
    "                if global_mean_mode == \"scalar\":\n",
    "                    # per-image scalar (paper): mean over channels and spatial\n",
    "                    wL_s = wL_native.mean(dim=(1,2,3), keepdim=True)\n",
    "                    wG_s = wG_native.mean(dim=(1,2,3), keepdim=True)\n",
    "                else:\n",
    "                    # legacy per-channel: mean over spatial only\n",
    "                    wL_s = wL_native.mean(dim=(2,3), keepdim=True)\n",
    "                    wG_s = wG_native.mean(dim=(2,3), keepdim=True)\n",
    "                wL = wL_s.expand_as(wL_native)\n",
    "                wG = wG_s.expand_as(wG_native)\n",
    "\n",
    "            elif override == \"shuffle\":\n",
    "                # shuffle across images AND channels with a single permutation applied to both gates\n",
    "                N, C, H, W = wL_native.shape\n",
    "                if N*C > 1:\n",
    "                    idx = torch.randperm(N*C, generator=rng, device=wL_native.device)\n",
    "                    wL = wL_native.reshape(N*C, H, W)[idx].reshape(N, C, H, W)\n",
    "                    wG = wG_native.reshape(N*C, H, W)[idx].reshape(N, C, H, W)\n",
    "\n",
    "            elif override == \"swap_lg\":\n",
    "                wL, wG = wG_native, wL_native\n",
    "\n",
    "            # sweep on top of whatever override we used\n",
    "            if alpha_local is not None:\n",
    "                wL = wL * float(alpha_local)\n",
    "                denom = wL + wG + 1e-6\n",
    "                wL = wL / denom\n",
    "                wG = wG / denom\n",
    "\n",
    "            # --- budget preservation: match sum of weights to native ---\n",
    "            # compute native sum budget (choose per-image scalar; switch to per-channel if you prefer)\n",
    "            s_native = (wL_native + wG_native).mean(dim=(1,2,3), keepdim=True)  # [N,1,1,1]\n",
    "            s_override = (wL + wG).mean(dim=(1,2,3), keepdim=True) + 1e-6\n",
    "            scale = s_native / s_override\n",
    "            wL = wL * scale\n",
    "            wG = wG * scale\n",
    "            # --- end budget preservation ---\n",
    "\n",
    "            out_core = wL * L + wG * G\n",
    "            return x + self.gamma * out_core\n",
    "\n",
    "        m.forward = types.MethodType(wrapped_forward, m)\n",
    "\n",
    "\n",
    "def _load_model_from_ckpt(ckpt_path, dataset_k, insert_level_hint=None, use_ema=True):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
    "    sd = ckpt.get(\"ema_state_dict\") if use_ema and (\"ema_state_dict\" in ckpt) else ckpt[\"model_state_dict\"]\n",
    "    sd = _strip_module_prefix(sd)\n",
    "\n",
    "    # infer anchors per location and confirm num classes\n",
    "    cls_w = None\n",
    "    for k in sd.keys():\n",
    "        if k.endswith(\"classification_head.cls_logits.weight\"):\n",
    "            cls_w = sd[k]; break\n",
    "    if cls_w is None:\n",
    "        raise KeyError(\"cls_logits.weight not found in checkpoint\")\n",
    "\n",
    "    out_ch = cls_w.shape[0]\n",
    "    if out_ch % dataset_k != 0:\n",
    "        # try regression head to find A\n",
    "        reg_w = None\n",
    "        for k in sd.keys():\n",
    "            if k.endswith(\"regression_head.bbox_regression.weight\"):\n",
    "                reg_w = sd[k]; break\n",
    "        A = reg_w.shape[0] // 4 if reg_w is not None else 9\n",
    "        K = out_ch // A\n",
    "        if K != dataset_k:\n",
    "            raise RuntimeError(f\"Class count mismatch. ckpt K={K}, dataset K={dataset_k}\")\n",
    "    # decide insert level\n",
    "    exp_name = str(ckpt.get(\"experiment_name\", \"\"))\n",
    "    candidates = [c for c in [\"C3\",\"C4\",\"C5\"]]\n",
    "    if insert_level_hint:\n",
    "        candidates = [insert_level_hint] + [c for c in candidates if c != insert_level_hint]\n",
    "    else:\n",
    "        parsed = _infer_insert_level_from_name(exp_name)\n",
    "        if parsed:\n",
    "            candidates = [parsed] + [c for c in candidates if c != parsed]\n",
    "\n",
    "    # try levels until keys fit best\n",
    "    best = None\n",
    "    best_score = None\n",
    "    for lvl in candidates:\n",
    "        m = build_model(dataset_k, lvl).to(device)\n",
    "        res = m.load_state_dict(sd, strict=False)\n",
    "        score = len(getattr(res, \"missing_keys\", [])) + len(getattr(res, \"unexpected_keys\", []))\n",
    "        if best is None or score < best_score:\n",
    "            best, best_score = (m, lvl), score\n",
    "        if score == 0:\n",
    "            break\n",
    "\n",
    "    model, level = best\n",
    "    model.eval()\n",
    "    return ckpt, model, level\n",
    "\n",
    "# def run_eval(\n",
    "#     mode, ckpt_path, *,\n",
    "#     dataset=\"coco_nw\",\n",
    "#     insert_level=None,\n",
    "#     gate_override=\"native\",\n",
    "#     gate_seed=None,\n",
    "#     gamma_mult=1.0,\n",
    "#     batch_size=4,\n",
    "#     num_workers=8,\n",
    "#     prefetch_factor=4,\n",
    "#     seed=42,\n",
    "#     speed=True,\n",
    "#     complexity=False,\n",
    "#     max_images_speed=200,\n",
    "#     val_img=None,\n",
    "#     val_ann=None,\n",
    "#     exp_name=None\n",
    "# ):\n",
    "#     # dataset and loader\n",
    "#     set_seed(seed)\n",
    "#     val_dataset, val_loader, va_ann = _build_val_loader(\n",
    "#         dataset, seed=seed, batch_size=batch_size, num_workers=num_workers,\n",
    "#         prefetch_factor=prefetch_factor, val_img=val_img, val_ann=val_ann\n",
    "#     )\n",
    "#     K = val_dataset.num_classes\n",
    "\n",
    "#     # build model from ckpt\n",
    "#     ckpt, model, level = _load_model_from_ckpt(ckpt_path, K, insert_level_hint=insert_level, use_ema=True)\n",
    "\n",
    "#     # sync CURRENT_CONFIG from ckpt when present, else from selected mode\n",
    "#     global CURRENT_CONFIG\n",
    "#     if \"config\" in ckpt:\n",
    "#         CURRENT_CONFIG = ckpt[\"config\"]\n",
    "#     else:\n",
    "#         CURRENT_CONFIG = CONFIG_MAP.get(mode, CONFIG_MAP[\"baseline\"])\n",
    "\n",
    "#     # patch gates\n",
    "#     _patch_gate_override(model, override=gate_override, gate_seed=gate_seed, gamma_mult=gamma_mult)\n",
    "\n",
    "#     # eval\n",
    "#     with torch.no_grad():\n",
    "#         metrics = coco_evaluation(model, val_loader, va_ann, device)\n",
    "\n",
    "#     # add optional speed/complexity\n",
    "#     out = {\n",
    "#         \"exp\": exp_name or \"control_eval\",\n",
    "#         \"checkpoint\": ckpt_path,\n",
    "#         \"mode\": mode,\n",
    "#         \"insert_level\": level,\n",
    "#         \"gate_override\": gate_override,\n",
    "#         \"gamma_mult\": gamma_mult,\n",
    "#         **metrics\n",
    "#     }\n",
    "#     if speed:\n",
    "#         out.update(benchmark_inference(model, val_loader, device, max_images=max_images_speed))\n",
    "#     if complexity:\n",
    "#         out.update(try_flops_params(model))\n",
    "\n",
    "    # print(json.dumps(out, indent=2))\n",
    "    # return out\n",
    "\n",
    "def run_eval(\n",
    "    mode, ckpt_path, *,\n",
    "    dataset=\"coco_nw\",\n",
    "    insert_level=None,\n",
    "    gate_override=\"native\",\n",
    "    gate_seed=None,\n",
    "    gamma_mult=1.0,\n",
    "    temp_mult=None,\n",
    "    temp_set=None,\n",
    "    alpha_local=None,           # new\n",
    "    global_mean_mode=\"scalar\",  # new\n",
    "    score_thresh=None,\n",
    "    batch_size=4,\n",
    "    num_workers=8,\n",
    "    prefetch_factor=4,\n",
    "    seed=42,\n",
    "    speed=True,\n",
    "    complexity=False,\n",
    "    max_images_speed=200,\n",
    "    val_img=None,\n",
    "    val_ann=None,\n",
    "    exp_name=None\n",
    "):\n",
    "    set_seed(seed)\n",
    "    # FIX: Ensure correct config is active before model creation\n",
    "    global CURRENT_CONFIG\n",
    "    try:\n",
    "        ckpt_tmp = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "        ckpt_cfg = ckpt_tmp.get(\"config\", None)\n",
    "        CURRENT_CONFIG = ckpt_cfg if ckpt_cfg is not None else CONFIG_MAP.get(mode, CONFIG_MAP[\"baseline\"])\n",
    "        del ckpt_tmp\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not read config from checkpoint ({e}), using default for mode={mode}\")\n",
    "        CURRENT_CONFIG = CONFIG_MAP.get(mode, CONFIG_MAP[\"baseline\"])\n",
    "\n",
    "\n",
    "    val_dataset, val_loader, va_ann = _build_val_loader(\n",
    "        dataset, seed=seed, batch_size=batch_size, num_workers=num_workers,\n",
    "        prefetch_factor=prefetch_factor, val_img=val_img, val_ann=val_ann\n",
    "    )\n",
    "    K = val_dataset.num_classes\n",
    "    ckpt, model, level = _load_model_from_ckpt(ckpt_path, K, insert_level_hint=insert_level, use_ema=True)\n",
    "\n",
    "    if score_thresh is not None:\n",
    "        model.score_thresh = float(score_thresh)\n",
    "\n",
    "    _patch_gate_override(\n",
    "        model,\n",
    "        override=gate_override,\n",
    "        gate_seed=gate_seed,\n",
    "        gamma_mult=gamma_mult,\n",
    "        temp_mult=temp_mult,\n",
    "        temp_set=temp_set,\n",
    "        alpha_local=alpha_local,\n",
    "        global_mean_mode=global_mean_mode\n",
    "    )\n",
    "\n",
    "    patched = sum(1 for m in model.modules() if m.__class__.__name__ == \"StableLGFBlock\")\n",
    "    assert patched > 0, f\"No lgf blocks found to patch. CURRENT_CONFIG={CURRENT_CONFIG}\"\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        metrics = coco_evaluation(model, val_loader, va_ann, device)\n",
    "\n",
    "    out = {\n",
    "        \"exp\": exp_name or \"control_eval\",\n",
    "        \"checkpoint\": ckpt_path,\n",
    "        \"mode\": mode,\n",
    "        \"insert_level\": level,\n",
    "        \"gate_override\": gate_override,\n",
    "        \"gamma_mult\": gamma_mult,\n",
    "        \"temp_mult\": temp_mult,\n",
    "        \"temp_set\": temp_set,\n",
    "        \"alpha_local\": alpha_local,\n",
    "        \"global_mean_mode\": global_mean_mode,\n",
    "        \"score_thresh\": score_thresh,\n",
    "        **metrics\n",
    "    }\n",
    "    if speed:\n",
    "        out.update(benchmark_inference(model, val_loader, device, max_images=max_images_speed))\n",
    "    if complexity:\n",
    "        out.update(try_flops_params(model))\n",
    "    print(json.dumps(out, indent=2))\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff67d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== BEST CHECKPOINTS DICT CELL ====\n",
    "from glob import glob\n",
    "\n",
    "def latest(pattern):\n",
    "    files = sorted(glob(pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(pattern)\n",
    "    return files[-1]\n",
    "\n",
    "# Fill this to match where you saved BEST_* files\n",
    "CKPT = {\n",
    "    # \"lgf_gated_spatial\": \"/nas.dbms/asera/NEW/4.1.2/BEST_coco_nw_C3_lgf_gated_spatial_s2025_epoch_70_map_0.3267_apsmall_0.2399.pth\", # NW\n",
    "    # \"lgf_gated_spatial\": \"/nas.dbms/asera/NEW/4.1.2/BEST_coco_weather_C3_lgf_gated_spatial_s42_epoch_70_map_0.2935_apsmall_0.1973.pth\", # Weather\n",
    "    \"lgf_gated_spatial\": \"/nas.dbms/asera/NEW/4.1.2/BEST_acdc_C3_lgf_gated_spatial_s1337_epoch_80_map_0.3305_apsmall_0.0866.pth\", # ACDC\n",
    "\n",
    "    # add others if you want\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONTROL RUNS  =====\n",
    "MODE   = \"lgf_gated_spatial\"\n",
    "CKPT   = CKPT[MODE]\n",
    "DATA   = \"acdc\"  # \"coco_nw\" | \"coco_weather\" | \"acdc\" | \"custom\"\n",
    "\n",
    "results = []\n",
    "\n",
    "# 1. Native\n",
    "results.append(run_eval(MODE, CKPT, dataset=DATA, exp_name=\"Native\",\n",
    "                        gate_override=\"native\", gamma_mult=1.0))\n",
    "\n",
    "# 2. Global-mean mask (per-image scalar)\n",
    "results.append(run_eval(MODE, CKPT, dataset=DATA, exp_name=\"Global-mean\",\n",
    "                        gate_override=\"global_mean\", global_mean_mode=\"scalar\", gamma_mult=1.0))\n",
    "\n",
    "# 3. Uniform 0.5/0.5\n",
    "results.append(run_eval(MODE, CKPT, dataset=DATA, exp_name=\"Uniform\",\n",
    "                        gate_override=\"uniform\", gamma_mult=1.0))\n",
    "\n",
    "# 4. Shuffle (images+channels)\n",
    "results.append(run_eval(MODE, CKPT, dataset=DATA, exp_name=\"Shuffle\",\n",
    "                        gate_override=\"shuffle\", gate_seed=123, gamma_mult=1.0))\n",
    "\n",
    "# 5. Swap local/global\n",
    "results.append(run_eval(MODE, CKPT, dataset=DATA, exp_name=\"Swap\",\n",
    "                        gate_override=\"swap_lg\", gamma_mult=1.0))\n",
    "\n",
    "# 6. -sweep (scale local gates, then renormalize)\n",
    "for a in [0.25, 0.5, 2.0]:\n",
    "    results.append(run_eval(MODE, CKPT, dataset=DATA, exp_name=f\"alpha_{a}\",\n",
    "                            gate_override=\"native\", alpha_local=a, gamma_mult=1.0))\n",
    "\n",
    "# 7. No module\n",
    "results.append(run_eval(MODE, CKPT, dataset=DATA, exp_name=\"No_module\",\n",
    "                        gate_override=\"no_module\", gamma_mult=1.0))\n",
    "\n",
    "# # 8. Local only\n",
    "# results.append(run_eval(MODE, CKPT, dataset=DATA, exp_name=\"only_local\",\n",
    "#                         gate_override=\"local_only\", gamma_mult=1.0))\n",
    "\n",
    "# # 9. Global only\n",
    "# results.append(run_eval(MODE, CKPT, dataset=DATA, exp_name=\"only_global\",\n",
    "#                         gate_override=\"global_only\", gamma_mult=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d865a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SUMMARY FUNCTION =====\n",
    "# # Install missing package when running in notebook\n",
    "# %pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def summarize_results(results, baseline_exp=\"Native\", baseline_override=\"native\"):\n",
    "    df = pd.DataFrame(results).copy()\n",
    "\n",
    "    # pick baseline row: first native without alpha override\n",
    "    alpha_col = 'alpha_local' if 'alpha_local' in df.columns else None\n",
    "    base_mask = (df.get('exp','') == baseline_exp) | (df.get('gate_override','') == baseline_override)\n",
    "    if alpha_col:\n",
    "        base_mask &= df[alpha_col].isna()\n",
    "    base = df[base_mask].iloc[0]\n",
    "\n",
    "    keep_cols = [\n",
    "        'exp','gate_override','alpha_local','insert_level',\n",
    "        'mAP','AP_small','AP50','AP75','AR100',\n",
    "        'detection_count','images_per_second'\n",
    "    ]\n",
    "    keep_cols = [c for c in keep_cols if c in df.columns]\n",
    "    tab = df[keep_cols].copy()\n",
    "\n",
    "    # deltas vs baseline\n",
    "    for c in ['mAP','AP_small','AP50','AP75','AR100']:\n",
    "        if c in tab.columns:\n",
    "            tab[f'{c}'] = tab[c] - float(base[c])\n",
    "\n",
    "    # tidy names and rounding\n",
    "    if 'detection_count' in tab.columns:\n",
    "        tab = tab.rename(columns={'detection_count':'dets'})\n",
    "        tab['dets'] = tab['dets'].astype(int)\n",
    "    if 'images_per_second' in tab.columns:\n",
    "        tab = tab.rename(columns={'images_per_second':'ips'})\n",
    "        tab['ips'] = tab['ips'].round(3)\n",
    "\n",
    "    for c in [x for x in tab.columns if x not in ('exp','gate_override','alpha_local','insert_level','dets')]:\n",
    "        tab[c] = tab[c].astype(float).round(4)\n",
    "\n",
    "    # order columns\n",
    "    ordered = [c for c in [\n",
    "        'exp','gate_override','alpha_local','insert_level',\n",
    "        'mAP','AP_small','AP50','AP75','AR100','dets','ips',\n",
    "        'mAP','AP_small','AP50','AP75','AR100'\n",
    "    ] if c in tab.columns]\n",
    "    tab = tab[ordered]\n",
    "\n",
    "    # sort by mAP desc if present\n",
    "    if 'mAP' in tab.columns:\n",
    "        tab = tab.sort_values('mAP', ascending=False)\n",
    "\n",
    "    # print a compact text table\n",
    "    print(tab.to_string(index=False))\n",
    "\n",
    "    # save\n",
    "    out_dir = Path(\"summaries\"); out_dir.mkdir(exist_ok=True, parents=True)\n",
    "    tab.to_csv(out_dir / \"controls_summary.csv\", index=False)\n",
    "\n",
    "    # LaTeX table for the paper\n",
    "    latex_cols = tab.rename(columns={\n",
    "        'exp':'Control',\n",
    "        'AP50':'AP$_{50}$','AP75':'AP$_{75}$',\n",
    "        'AP_small':'AP$_{S}$','AR100':'AR$_{100}$',\n",
    "        'mAP':'$\\\\Delta$ mAP','AP_small':'$\\\\Delta$ AP$_{S}$',\n",
    "        'AP50':'$\\\\Delta$ AP$_{50}$','AP75':'$\\\\Delta$ AP$_{75}$',\n",
    "        'AR100':'$\\\\Delta$ AR$_{100}$'\n",
    "    })\n",
    "    tex = latex_cols.to_latex(index=False, escape=False, float_format=\"%.4f\")\n",
    "    (out_dir / \"controls_summary.tex\").write_text(tex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a12479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after you append all run_eval outputs into `results`\n",
    "summarize_results(results, baseline_exp=\"Native\", baseline_override=\"native\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEST1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
